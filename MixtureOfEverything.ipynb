{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb3b6f7-a081-4ae8-9ac9-fb2858bae619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Set HuggingFace cache directory to scratch to save space.\n",
    "import os\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/scratch/' + os.environ['USER'] + '/huggingface_cache'\n",
    "CACHE_DIR = '/scratch/' + os.environ['USER'] + '/huggingface_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29031229-75ac-410f-8d69-b7a08bdb5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import hnswlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebf1e32c-00e9-4b23-95ae-bbfbaeaf130f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec5de72416d4ba4833a2e79536c4ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e772d87d-879b-425f-a391-fbdb979b63bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10240, 2560]), torch.Size([2560, 10240]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].mlp.fc1.weight.shape, model.model.layers[0].mlp.fc2.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "faf40842-ba84-43d7-9bc7-05549beb1d86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "from transformers.activations import ACT2FN\n",
    "\n",
    "class PhiMLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.activation_fn = ACT2FN[config.hidden_act]\n",
    "        self.fc1 = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        self.fc2 = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.fc1(hidden_states)\n",
    "        hidden_states = self.activation_fn(hidden_states)\n",
    "        hidden_states = self.fc2(hidden_states)\n",
    "        return hidden_states\n",
    "\"\"\"\n",
    "\n",
    "debug_acts = None\n",
    "\n",
    "class SparseMLP(torch.nn.Module):\n",
    "    def __init__(self, mlp, num_neighbors, p=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Use inner product as a \"distance metric\". This is actually perfect for our case though,\n",
    "        # where MLP activations are scaled according to inner product.\n",
    "        self.mlp = mlp\n",
    "        if p is not None:\n",
    "            self.p = p\n",
    "        else:\n",
    "            self.p = p = hnswlib.Index(space='ip', dim=mlp.fc1.in_features + 1)\n",
    "\n",
    "            # Add weight matrix to encoder.\n",
    "            p.init_index(max_elements=mlp.fc1.out_features)\n",
    "\n",
    "            ids = np.arange(mlp.fc1.out_features)\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            # mlp.fc1.weight.shape: [10240, 2560]\n",
    "            # we add a bias so we can query for that inner product as well\n",
    "            match_vecs = np.concatenate([\n",
    "                mlp.fc1.weight.detach().cpu().numpy(),\n",
    "                mlp.fc1.bias.detach().cpu().unsqueeze(-1).numpy(),\n",
    "            ], axis=-1)\n",
    "            p.add_items(match_vecs, ids)\n",
    "\n",
    "            end_time = time.time()\n",
    "\n",
    "            print(f\"Initialized HNSW database in {end_time - start_time:.4f}s\")\n",
    "\n",
    "        # ef should be greater than k.\n",
    "        # it is the size of the list used during nearest neighbor search.\n",
    "        p.set_ef(int(num_neighbors * 2))\n",
    "        self.num_neighbors = num_neighbors\n",
    "    \n",
    "    def forward(self, hidden_states: torch.Tensor):\n",
    "        global debug_acts\n",
    "        \n",
    "        hidden_states_np = np.ones((hidden_states.shape[0], hidden_states.shape[1], hidden_states.shape[2] + 1))\n",
    "        hidden_states_np[..., :-1] = hidden_states.detach().cpu().numpy()\n",
    "        # Flatten.\n",
    "        hidden_states_np_flat = hidden_states_np.reshape(-1, hidden_states_np.shape[-1])\n",
    "        # Calculate nearest neighbors.\n",
    "        # Discard these distances, as they might be inaccurate. TODO: Quantify this?\n",
    "        # print(\"Performing KNN query.\")\n",
    "        start = time.time()\n",
    "        labels_flat, _distances = self.p.knn_query(hidden_states_np_flat, k=self.num_neighbors)\n",
    "        labels_flat = torch.tensor(labels_flat.astype(np.int64), device=\"cuda\").long()\n",
    "        labels = labels_flat.view((hidden_states.shape[0], hidden_states.shape[1], self.num_neighbors))\n",
    "        end = time.time()\n",
    "        # print(f\"KNN query finished: {end - start:.4f}s\")\n",
    "        # labels = labels.reshape((hidden_states.shape[0], hidden_states.shape[1], num_neighbors))\n",
    "        \n",
    "        # TODO: Cache contributions from MLP neurons with 0 bias?\n",
    "        mlp = self.mlp\n",
    "        # activations_recons_flat = torch.zeros((hidden_states.shape[0] * hidden_states.shape[1], mlp.fc1.bias.shape[0]), device=mlp.fc1.bias.device, dtype=mlp.fc1.bias.dtype)\n",
    "        \n",
    "        activations_recons = torch.zeros((hidden_states.shape[0], hidden_states.shape[1], mlp.fc1.bias.shape[0]), device=mlp.fc1.bias.device, dtype=mlp.fc1.bias.dtype)\n",
    "        activations_recons -= 0.28\n",
    "        \n",
    "        # Construct activations manually.\n",
    "        for batch_i in range(hidden_states.shape[0]):\n",
    "            for seq_i in range(hidden_states.shape[1]):\n",
    "                # for nearest_fc1_vector_id in range(10240):\n",
    "                for label_i in range(self.num_neighbors):\n",
    "                    nearest_fc1_vector_id = labels[batch_i, seq_i, label_i]\n",
    "                    activations_recons[batch_i, seq_i, nearest_fc1_vector_id] = mlp.fc1.weight.data[nearest_fc1_vector_id, :] @ hidden_states[batch_i, seq_i]\n",
    "        \n",
    "        activations_recons[:] += mlp.fc1.bias.data.clone()\n",
    "        \n",
    "        true_activations = mlp.fc1(hidden_states)\n",
    "        \n",
    "        debug_acts = (activations_recons, true_activations)\n",
    "        \n",
    "        # print(activations_recons)\n",
    "        # print(true_activations)\n",
    "        \n",
    "        # [batch_size, seqlen, hidden dims size]\n",
    "        \n",
    "#         labels_flatter = labels_flat.view(-1)\n",
    "        \n",
    "#         mlp_selected = mlp.fc1.weight.data[:, labels_flatter].view(-1, hidden_states.shape[0], self.num_neighbors)\n",
    "        \n",
    "#         print(labels_flatter.shape, mlp_selected.shape)\n",
    "#         return\n",
    "        \n",
    "#         # (out_dims, in_dims) x (n_tokens, in_dims) -> (n_tokens, out_dims)\n",
    "#         activations_recons_flat[:, labels_flat] += torch.einsum(\"oi,ni->no\", mlp.fc1.weight.data[:, labels_flat], hidden_states)\n",
    "#         activations_flat = mlp.activation_fn(activations_recons_flat)\n",
    "#         print(activations_recons_flat.shape, activations_flat.shape)\n",
    "#         activations = activations_flat.view(hidden_states.shape[0], hidden_states.shape[1], mlp.fc1.bias.shape[0])\n",
    "#         print(activations.shape)\n",
    "        \n",
    "        # Construct output. As I mentioned earlier, we can cache contributions from activations that are common constants.\n",
    "        reconstructed_activation = torch.einsum(\"oi,bsi->bso\", mlp.fc2.weight, mlp.activation_fn(activations_recons)) + mlp.fc2.bias\n",
    "        \n",
    "        end_2 = time.time()\n",
    "        print(f\"Total sparse runtime: {end_2 - start:.4f}s\")\n",
    "        \n",
    "        mlp_start = time.time()\n",
    "        original_activation = mlp(hidden_states)\n",
    "        mlp_end = time.time()\n",
    "        \n",
    "        print(f\"MLP runtime: {mlp_end - mlp_start:.4f}s\")\n",
    "        \n",
    "        pre = torch.abs(true_activations - activations_recons).sum().item()\n",
    "        post = torch.abs(mlp.activation_fn(true_activations) - mlp.activation_fn(activations_recons)).sum().item()\n",
    "        out = torch.abs(original_activation - reconstructed_activation).sum().item()\n",
    "        print(f\"err: {pre=:.4f} {post=:.4f} {out=:.4f}\")\n",
    "        \n",
    "        return reconstructed_activation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffb8ac-a08c-4edc-a407-078cb9401141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While this doesn't look great, let's try to do this for later layers. Maybe it's just very bad for the first 1-2 layers only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e97ae500-9c4c-4aef-ab7e-5f69c4f33629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "original_mlps = [model.model.layers[i].mlp for i in range(len(model.model.layers))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0218b878-7e3b-4558-8270-1289371554ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ZeroMLP(torch.nn.Module):\n",
    "    def __init__(self, mlp):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.mlp = mlp\n",
    "        \n",
    "    def forward(self, hidden_states):\n",
    "        return torch.zeros_like(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e76db4ec-9c2a-4a2d-97e1-7f4fd783193b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized HNSW database in 20.8995s\n",
      "Initialized HNSW database in 29.8869s\n",
      "Initialized HNSW database in 30.0281s\n",
      "Initialized HNSW database in 17.2247s\n",
      "Initialized HNSW database in 23.6389s\n",
      "Initialized HNSW database in 20.9169s\n",
      "Initialized HNSW database in 21.1710s\n",
      "Initialized HNSW database in 22.7189s\n",
      "Initialized HNSW database in 33.1878s\n",
      "Initialized HNSW database in 28.4556s\n",
      "Initialized HNSW database in 34.6641s\n",
      "Initialized HNSW database in 34.8667s\n",
      "Initialized HNSW database in 34.6308s\n",
      "Initialized HNSW database in 33.8913s\n",
      "Initialized HNSW database in 33.4640s\n",
      "Initialized HNSW database in 34.4231s\n",
      "Initialized HNSW database in 33.7416s\n",
      "Initialized HNSW database in 36.4866s\n",
      "Initialized HNSW database in 35.4536s\n",
      "Initialized HNSW database in 34.1627s\n",
      "Initialized HNSW database in 43.3786s\n",
      "Initialized HNSW database in 45.1103s\n",
      "Initialized HNSW database in 44.0910s\n",
      "Initialized HNSW database in 44.1231s\n",
      "Initialized HNSW database in 43.8215s\n",
      "Initialized HNSW database in 43.0289s\n",
      "Initialized HNSW database in 36.2370s\n"
     ]
    }
   ],
   "source": [
    "cache_all = []\n",
    "for mlp_i in range(32):\n",
    "    if 20 <= mlp_i <= 24:\n",
    "        cache_all.append(cache[mlp_i - 20])\n",
    "    else:\n",
    "        cache_all.append(SparseMLP(original_mlps[mlp_i], num_neighbors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c2c3599b-412d-4177-b984-a1fff42f653a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(cache_all)):\n",
    "    cache_all[i].p.save_index(f\"index_{i}.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f12881-a541-4869-8f09-721c65048f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache = [model.model.layers[mlp_i].mlp for mlp_i in replace_mlps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2548f8af-e5b7-44cb-bc20-38e71a4b68ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "replace_mlps = [20, 21, 22, 23, 24]\n",
    "num_neighbors = 50\n",
    "\n",
    "# cache = [model.model.layers[mlp_i].mlp for mlp_i in replace_mlps]\n",
    "\n",
    "for mlp_i in range(len(model.model.layers)):\n",
    "    if mlp_i in replace_mlps:\n",
    "        cur = model.model.layers[mlp_i].mlp\n",
    "        model.model.layers[mlp_i].mlp = cache[replace_mlps.index(mlp_i)]\n",
    "        # model.model.layers[mlp_i].mlp = ZeroMLP(cur)\n",
    "        # model.model.layers[mlp_i].mlp = SparseMLP(original_mlps[mlp_i], num_neighbors, p=cur.p if type(cur) != type(model.model.layers[0].mlp) else None)\n",
    "    else:\n",
    "        # if we change replace_mlps, then restore the old mlp layer\n",
    "        model.model.layers[mlp_i].mlp = original_mlps[mlp_i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7807c7af-f41f-49bf-b398-f39780523b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "smlp = model.model.layers[23].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dd23f9c5-66e9-4c6d-923b-b2af63cb2870",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sparse runtime: 0.0921s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=inf post=9808.0000 out=6860.0000\n",
      "Total sparse runtime: 0.0885s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=inf post=10584.0000 out=8544.0000\n",
      "Total sparse runtime: 0.0754s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=inf post=11488.0000 out=9128.0000\n",
      "Total sparse runtime: 0.0781s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=inf post=12072.0000 out=10032.0000\n",
      "Total sparse runtime: 0.0758s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=inf post=13080.0000 out=11128.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9456.0000 post=769.5000 out=708.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8872.0000 post=889.0000 out=883.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=1036.0000 out=1107.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8880.0000 post=1139.0000 out=1254.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9216.0000 post=1261.0000 out=1495.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9272.0000 post=750.0000 out=714.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=858.5000 out=864.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=981.5000 out=1051.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=1099.0000 out=1190.0000\n",
      "Total sparse runtime: 0.0088s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9216.0000 post=1233.0000 out=1471.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9176.0000 post=628.5000 out=567.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9800.0000 post=696.5000 out=801.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9016.0000 post=724.0000 out=936.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8664.0000 post=950.0000 out=1299.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8752.0000 post=1151.0000 out=1590.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9472.0000 post=643.0000 out=615.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=689.5000 out=869.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8640.0000 post=790.5000 out=923.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9920.0000 post=774.5000 out=829.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9912.0000 post=922.0000 out=1121.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9280.0000 post=757.5000 out=699.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=843.0000 out=862.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9144.0000 post=971.0000 out=1005.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9416.0000 post=948.5000 out=1012.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9544.0000 post=973.0000 out=1105.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9368.0000 post=796.5000 out=753.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8888.0000 post=885.5000 out=894.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=1039.0000 out=1059.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9368.0000 post=1005.5000 out=1087.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9448.0000 post=1001.0000 out=1142.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=678.5000 out=596.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8944.0000 post=753.0000 out=748.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8880.0000 post=809.0000 out=807.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=831.0000 out=840.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9480.0000 post=807.0000 out=859.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=705.0000 out=619.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=757.0000 out=735.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8616.0000 post=879.0000 out=891.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8768.0000 post=993.0000 out=1094.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=1019.5000 out=1191.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8808.0000 post=777.5000 out=639.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=872.5000 out=909.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=1016.5000 out=1143.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8216.0000 post=1236.0000 out=1389.0000\n",
      "Total sparse runtime: 0.0089s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8760.0000 post=1270.0000 out=1459.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8376.0000 post=690.0000 out=644.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8616.0000 post=724.5000 out=689.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8352.0000 post=800.0000 out=904.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7936.0000 post=895.5000 out=986.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8624.0000 post=889.0000 out=1042.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=790.0000 out=667.0000\n",
      "Total sparse runtime: 0.0189s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7944.0000 post=811.0000 out=828.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8064.0000 post=924.0000 out=963.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8376.0000 post=1046.0000 out=1111.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8416.0000 post=1033.0000 out=1180.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8472.0000 post=751.5000 out=597.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=806.0000 out=880.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7840.0000 post=975.5000 out=1260.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7748.0000 post=1204.0000 out=1446.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8576.0000 post=1268.0000 out=1535.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8704.0000 post=776.5000 out=637.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8440.0000 post=831.0000 out=896.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7896.0000 post=1025.0000 out=1145.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8680.0000 post=1025.0000 out=1085.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8984.0000 post=1081.0000 out=1226.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8768.0000 post=796.5000 out=682.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=819.0000 out=855.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7880.0000 post=959.0000 out=1215.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8888.0000 post=1002.0000 out=1136.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8792.0000 post=1010.5000 out=1191.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8840.0000 post=820.0000 out=661.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8864.0000 post=863.0000 out=832.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8160.0000 post=975.0000 out=1062.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9168.0000 post=1089.0000 out=1201.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9056.0000 post=1063.0000 out=1230.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8200.0000 post=676.5000 out=571.5000\n",
      "Total sparse runtime: 0.0079s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8264.0000 post=723.0000 out=688.0000\n",
      "Total sparse runtime: 0.0392s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8040.0000 post=761.5000 out=734.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=815.0000 out=838.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=777.0000 out=813.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8624.0000 post=706.5000 out=614.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8200.0000 post=775.5000 out=750.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8416.0000 post=822.5000 out=798.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=907.5000 out=933.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=931.0000 out=1020.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=764.0000 out=604.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8192.0000 post=825.5000 out=836.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8040.0000 post=953.5000 out=973.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=1047.0000 out=1136.0000\n",
      "Total sparse runtime: 0.0096s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8368.0000 post=1146.0000 out=1330.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8368.0000 post=741.5000 out=601.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8032.0000 post=821.0000 out=813.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8020.0000 post=950.5000 out=1005.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7844.0000 post=1073.0000 out=1143.0000\n",
      "Total sparse runtime: 0.0086s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8536.0000 post=1105.0000 out=1251.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8912.0000 post=789.0000 out=685.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8384.0000 post=849.0000 out=794.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8352.0000 post=943.5000 out=1032.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8088.0000 post=1123.0000 out=1273.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=1160.0000 out=1327.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9296.0000 post=796.5000 out=645.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8976.0000 post=855.0000 out=803.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8808.0000 post=976.5000 out=970.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=1117.0000 out=1178.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9392.0000 post=1241.0000 out=1386.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=663.5000 out=580.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8172.0000 post=673.5000 out=653.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=713.5000 out=695.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8872.0000 post=784.5000 out=827.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=782.0000 out=847.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8032.0000 post=775.5000 out=618.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8056.0000 post=804.0000 out=749.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7840.0000 post=865.0000 out=837.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8032.0000 post=947.5000 out=1009.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7928.0000 post=1047.0000 out=1176.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7904.0000 post=682.5000 out=509.7500\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8128.0000 post=751.5000 out=813.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7348.0000 post=851.0000 out=912.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=909.0000 out=945.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8144.0000 post=991.5000 out=1152.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7688.0000 post=694.5000 out=513.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7836.0000 post=744.5000 out=729.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7740.0000 post=806.0000 out=725.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8096.0000 post=889.5000 out=903.5000\n",
      "Total sparse runtime: 0.0071s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8264.0000 post=914.5000 out=989.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7724.0000 post=786.0000 out=599.5000\n",
      "Total sparse runtime: 0.0083s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8016.0000 post=851.0000 out=1102.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7188.0000 post=974.5000 out=1042.0000\n",
      "Total sparse runtime: 0.0070s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8052.0000 post=937.5000 out=912.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7888.0000 post=942.5000 out=1026.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7732.0000 post=737.0000 out=576.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8240.0000 post=786.0000 out=868.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8048.0000 post=823.5000 out=807.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7116.0000 post=986.0000 out=1055.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8100.0000 post=938.0000 out=1015.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7932.0000 post=738.0000 out=614.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8140.0000 post=796.0000 out=880.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8108.0000 post=818.0000 out=810.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8000.0000 post=874.5000 out=902.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8188.0000 post=872.0000 out=952.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8760.0000 post=708.0000 out=588.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8696.0000 post=764.5000 out=761.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8848.0000 post=813.5000 out=780.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9128.0000 post=899.0000 out=987.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8896.0000 post=908.0000 out=994.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9368.0000 post=693.0000 out=650.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8752.0000 post=697.5000 out=706.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8960.0000 post=725.5000 out=742.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9384.0000 post=802.0000 out=847.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=953.0000 out=1117.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9528.0000 post=657.0000 out=646.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9328.0000 post=707.5000 out=681.0000\n",
      "Total sparse runtime: 0.0072s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9848.0000 post=712.5000 out=759.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9424.0000 post=815.0000 out=979.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9664.0000 post=995.0000 out=1273.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9304.0000 post=565.0000 out=499.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9928.0000 post=596.5000 out=569.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10104.0000 post=600.0000 out=526.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10720.0000 post=620.5000 out=617.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11000.0000 post=648.0000 out=676.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9256.0000 post=642.0000 out=583.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9696.0000 post=678.5000 out=769.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0005s\n",
      "err: pre=8728.0000 post=735.0000 out=801.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10168.0000 post=710.5000 out=699.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10576.0000 post=715.5000 out=737.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9152.0000 post=762.0000 out=654.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=834.0000 out=770.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9048.0000 post=917.0000 out=911.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9104.0000 post=918.0000 out=931.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9328.0000 post=893.5000 out=975.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=675.5000 out=606.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8880.0000 post=741.0000 out=692.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=778.5000 out=735.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8720.0000 post=811.5000 out=807.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=781.5000 out=802.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8728.0000 post=714.5000 out=619.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8872.0000 post=766.0000 out=828.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0021s\n",
      "err: pre=8216.0000 post=887.5000 out=977.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=928.0000 out=1021.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=909.5000 out=1110.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8560.0000 post=746.0000 out=637.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8368.0000 post=837.0000 out=844.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8288.0000 post=959.0000 out=948.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8576.0000 post=1041.0000 out=1089.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8384.0000 post=1047.0000 out=1121.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=805.5000 out=662.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8464.0000 post=873.5000 out=862.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8600.0000 post=1036.0000 out=1035.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=1120.0000 out=1174.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8848.0000 post=1231.0000 out=1455.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8256.0000 post=741.0000 out=616.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8052.0000 post=817.0000 out=873.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8176.0000 post=941.0000 out=931.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=1039.0000 out=1081.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8408.0000 post=1092.0000 out=1216.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=665.0000 out=584.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8440.0000 post=693.0000 out=712.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8584.0000 post=719.5000 out=744.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=744.5000 out=739.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9328.0000 post=707.5000 out=794.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8488.0000 post=701.0000 out=656.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7832.0000 post=769.0000 out=762.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8168.0000 post=825.0000 out=801.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8528.0000 post=869.0000 out=876.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=856.0000 out=957.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8584.0000 post=771.0000 out=623.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8156.0000 post=831.0000 out=816.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8056.0000 post=951.0000 out=1051.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7748.0000 post=1097.0000 out=1214.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8432.0000 post=1166.0000 out=1295.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8232.0000 post=757.0000 out=605.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8240.0000 post=803.5000 out=766.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7920.0000 post=900.0000 out=969.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7676.0000 post=1045.0000 out=1130.0000\n",
      "Total sparse runtime: 0.0086s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8248.0000 post=1007.5000 out=1112.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8368.0000 post=776.0000 out=589.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7892.0000 post=833.0000 out=770.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7996.0000 post=973.0000 out=979.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7700.0000 post=1110.0000 out=1114.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8056.0000 post=1132.0000 out=1292.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8020.0000 post=744.0000 out=586.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8072.0000 post=783.5000 out=777.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7228.0000 post=867.0000 out=806.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7848.0000 post=854.5000 out=831.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8040.0000 post=813.0000 out=855.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8256.0000 post=772.0000 out=592.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7920.0000 post=841.5000 out=803.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7376.0000 post=979.5000 out=941.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8012.0000 post=967.0000 out=966.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7828.0000 post=896.5000 out=952.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8092.0000 post=707.0000 out=533.5000\n",
      "Total sparse runtime: 0.0080s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=791.0000 out=799.0000\n",
      "Total sparse runtime: 0.0298s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7664.0000 post=845.0000 out=809.0000\n",
      "Total sparse runtime: 0.0070s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=872.0000 out=855.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8296.0000 post=823.5000 out=931.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7596.0000 post=702.0000 out=605.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7764.0000 post=738.5000 out=713.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7388.0000 post=786.5000 out=775.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7980.0000 post=801.5000 out=811.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7952.0000 post=772.0000 out=821.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=690.0000 out=583.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9056.0000 post=746.5000 out=700.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9232.0000 post=751.0000 out=811.5000\n",
      "Total sparse runtime: 0.0070s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=860.0000 out=969.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9640.0000 post=811.0000 out=911.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9880.0000 post=759.5000 out=698.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9160.0000 post=778.5000 out=763.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9160.0000 post=817.0000 out=829.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9320.0000 post=885.5000 out=954.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9232.0000 post=1007.5000 out=1156.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9360.0000 post=607.0000 out=549.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9928.0000 post=638.5000 out=596.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10064.0000 post=636.0000 out=633.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10640.0000 post=649.0000 out=602.5000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11112.0000 post=676.5000 out=668.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9120.0000 post=599.0000 out=528.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9512.0000 post=598.0000 out=553.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9576.0000 post=603.5000 out=555.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10608.0000 post=625.5000 out=590.5000\n",
      "Total sparse runtime: 0.0071s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11168.0000 post=615.0000 out=612.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9024.0000 post=772.0000 out=679.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8432.0000 post=819.0000 out=835.5000\n",
      "Total sparse runtime: 0.0070s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8712.0000 post=875.5000 out=884.5000\n",
      "Total sparse runtime: 0.0089s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8952.0000 post=923.5000 out=954.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9352.0000 post=886.0000 out=1025.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=758.0000 out=663.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8104.0000 post=831.0000 out=877.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8472.0000 post=910.5000 out=872.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8720.0000 post=971.0000 out=1034.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8776.0000 post=1021.0000 out=1213.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=665.0000 out=571.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=705.0000 out=653.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8200.0000 post=769.0000 out=728.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8664.0000 post=814.0000 out=808.5000\n",
      "Total sparse runtime: 0.0193s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8936.0000 post=793.5000 out=821.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=764.5000 out=645.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8456.0000 post=811.5000 out=799.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=933.5000 out=1065.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=1091.0000 out=1355.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8528.0000 post=1213.0000 out=1536.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8640.0000 post=800.0000 out=672.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8320.0000 post=857.5000 out=863.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=987.5000 out=1004.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=1119.0000 out=1237.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8520.0000 post=1181.0000 out=1388.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8792.0000 post=778.5000 out=666.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8560.0000 post=791.0000 out=872.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7956.0000 post=894.5000 out=1037.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8712.0000 post=864.5000 out=855.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9360.0000 post=885.0000 out=967.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8936.0000 post=799.5000 out=606.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8920.0000 post=864.0000 out=796.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=982.0000 out=1048.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8576.0000 post=1100.0000 out=1205.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9232.0000 post=1122.0000 out=1265.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8052.0000 post=652.0000 out=527.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=673.0000 out=702.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7412.0000 post=734.5000 out=741.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=704.5000 out=676.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9248.0000 post=674.0000 out=821.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8512.0000 post=727.0000 out=629.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8020.0000 post=769.5000 out=720.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8464.0000 post=850.0000 out=798.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8608.0000 post=897.0000 out=879.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8680.0000 post=860.5000 out=976.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8504.0000 post=752.5000 out=593.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8328.0000 post=772.0000 out=822.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7828.0000 post=883.0000 out=905.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8680.0000 post=900.0000 out=920.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=939.0000 out=1088.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8240.0000 post=744.5000 out=578.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8148.0000 post=791.0000 out=843.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7672.0000 post=942.5000 out=977.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=956.5000 out=980.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8512.0000 post=1009.5000 out=1151.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8512.0000 post=763.5000 out=581.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=790.5000 out=720.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=925.0000 out=865.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=970.0000 out=947.0000\n",
      "Total sparse runtime: 0.0071s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8928.0000 post=997.5000 out=1076.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8152.0000 post=728.5000 out=591.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8256.0000 post=761.0000 out=844.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7932.0000 post=790.0000 out=880.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7376.0000 post=856.0000 out=984.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8472.0000 post=796.0000 out=880.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8384.0000 post=787.5000 out=596.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8224.0000 post=829.0000 out=734.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8084.0000 post=939.0000 out=961.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7664.0000 post=1027.0000 out=1092.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8296.0000 post=964.0000 out=1056.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7712.0000 post=711.0000 out=592.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8052.0000 post=747.5000 out=788.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7756.0000 post=771.0000 out=696.5000\n",
      "Total sparse runtime: 0.0087s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8056.0000 post=767.5000 out=728.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8256.0000 post=685.0000 out=811.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7716.0000 post=740.0000 out=541.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7884.0000 post=772.0000 out=872.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7140.0000 post=832.0000 out=827.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=862.5000 out=789.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=757.0000 out=748.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8080.0000 post=686.5000 out=542.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8392.0000 post=713.0000 out=746.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8176.0000 post=715.0000 out=681.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=718.0000 out=677.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9104.0000 post=659.5000 out=703.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8456.0000 post=652.0000 out=544.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8520.0000 post=679.5000 out=642.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8648.0000 post=693.5000 out=613.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8920.0000 post=745.5000 out=702.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8768.0000 post=672.5000 out=705.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9560.0000 post=728.5000 out=669.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8840.0000 post=738.0000 out=891.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8208.0000 post=823.0000 out=897.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9656.0000 post=877.5000 out=887.5000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9888.0000 post=993.0000 out=1121.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9152.0000 post=637.0000 out=596.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8728.0000 post=684.0000 out=673.5000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8928.0000 post=696.0000 out=693.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9552.0000 post=752.5000 out=818.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9824.0000 post=851.5000 out=976.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=609.5000 out=561.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9432.0000 post=644.5000 out=639.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9360.0000 post=636.0000 out=612.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9848.0000 post=681.0000 out=668.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10592.0000 post=704.0000 out=729.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8712.0000 post=645.5000 out=589.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9064.0000 post=681.0000 out=670.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9160.0000 post=679.5000 out=654.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9440.0000 post=726.0000 out=708.0000\n",
      "Total sparse runtime: 0.0084s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9896.0000 post=676.5000 out=677.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8712.0000 post=701.0000 out=591.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=746.5000 out=700.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=769.0000 out=739.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8576.0000 post=852.5000 out=832.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8088.0000 post=784.0000 out=885.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=644.5000 out=548.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=716.5000 out=647.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7988.0000 post=731.0000 out=703.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=771.0000 out=742.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8656.0000 post=722.5000 out=753.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8728.0000 post=695.0000 out=587.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=726.5000 out=741.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7888.0000 post=766.5000 out=750.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8648.0000 post=829.5000 out=836.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8728.0000 post=702.0000 out=775.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=700.5000 out=593.0000\n",
      "Total sparse runtime: 0.0081s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8656.0000 post=750.5000 out=685.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8036.0000 post=744.5000 out=662.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=807.0000 out=792.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8116.0000 post=707.5000 out=769.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=711.5000 out=580.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8528.0000 post=746.0000 out=739.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7568.0000 post=820.5000 out=796.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8768.0000 post=844.0000 out=793.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8504.0000 post=806.0000 out=886.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7924.0000 post=649.0000 out=557.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8296.0000 post=714.5000 out=692.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7856.0000 post=790.0000 out=734.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=831.5000 out=820.0000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8336.0000 post=745.5000 out=790.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=616.0000 out=549.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9408.0000 post=665.5000 out=621.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=648.0000 out=597.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9600.0000 post=666.5000 out=643.0000\n",
      "Total sparse runtime: 0.0082s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10056.0000 post=598.0000 out=594.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=655.0000 out=599.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8096.0000 post=704.5000 out=676.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=696.0000 out=637.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9216.0000 post=772.5000 out=779.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9128.0000 post=667.0000 out=741.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8512.0000 post=647.5000 out=560.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9016.0000 post=719.5000 out=651.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=736.0000 out=683.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9096.0000 post=787.0000 out=775.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=661.0000 out=702.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8624.0000 post=667.5000 out=574.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8984.0000 post=734.0000 out=678.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=726.5000 out=670.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=791.5000 out=797.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8696.0000 post=668.5000 out=722.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8656.0000 post=666.5000 out=535.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9048.0000 post=743.0000 out=724.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7872.0000 post=764.0000 out=733.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9336.0000 post=840.5000 out=835.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=739.0000 out=781.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8136.0000 post=636.0000 out=533.5000\n",
      "Total sparse runtime: 0.0086s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8888.0000 post=699.5000 out=631.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8288.0000 post=698.0000 out=637.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8584.0000 post=769.0000 out=768.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8592.0000 post=652.5000 out=678.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8536.0000 post=699.5000 out=542.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9016.0000 post=755.0000 out=644.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8416.0000 post=772.5000 out=701.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8536.0000 post=839.5000 out=846.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8560.0000 post=703.0000 out=735.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8264.0000 post=655.0000 out=539.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8784.0000 post=707.5000 out=594.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8392.0000 post=745.0000 out=666.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8664.0000 post=800.0000 out=774.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8896.0000 post=706.5000 out=722.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7948.0000 post=617.0000 out=534.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8976.0000 post=676.0000 out=624.0000\n",
      "Total sparse runtime: 0.0083s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8584.0000 post=698.0000 out=676.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9184.0000 post=719.0000 out=768.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10112.0000 post=637.0000 out=609.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9048.0000 post=640.5000 out=559.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9696.0000 post=686.5000 out=665.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9264.0000 post=679.0000 out=641.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9520.0000 post=714.5000 out=706.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9680.0000 post=688.0000 out=691.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9840.0000 post=734.5000 out=608.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9816.0000 post=779.0000 out=749.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=815.0000 out=842.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9568.0000 post=796.0000 out=825.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9904.0000 post=882.0000 out=1034.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9720.0000 post=580.0000 out=519.0000\n",
      "Total sparse runtime: 0.0080s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10288.0000 post=612.5000 out=566.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10176.0000 post=610.5000 out=546.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11040.0000 post=613.5000 out=598.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11640.0000 post=640.0000 out=628.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9112.0000 post=675.5000 out=613.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9464.0000 post=702.5000 out=660.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9504.0000 post=706.0000 out=677.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10000.0000 post=705.5000 out=683.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10640.0000 post=686.0000 out=681.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8888.0000 post=758.5000 out=660.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8840.0000 post=799.5000 out=767.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8992.0000 post=809.0000 out=771.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9200.0000 post=862.0000 out=875.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9656.0000 post=821.0000 out=941.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8280.0000 post=652.5000 out=534.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=727.0000 out=708.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=768.5000 out=733.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8640.0000 post=774.0000 out=753.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8776.0000 post=746.5000 out=784.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8760.0000 post=763.0000 out=631.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8344.0000 post=798.5000 out=767.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8440.0000 post=898.0000 out=915.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8752.0000 post=991.5000 out=1116.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8760.0000 post=999.5000 out=1183.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8464.0000 post=785.0000 out=634.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=856.0000 out=843.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8264.0000 post=970.0000 out=1002.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8520.0000 post=1055.0000 out=1120.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8648.0000 post=1109.0000 out=1281.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=797.0000 out=683.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=808.5000 out=764.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=932.5000 out=1004.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=934.0000 out=974.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9032.0000 post=922.0000 out=1035.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=826.5000 out=676.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8728.0000 post=867.5000 out=811.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=997.5000 out=1068.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8696.0000 post=1107.0000 out=1230.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=1180.0000 out=1335.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8808.0000 post=764.5000 out=630.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8600.0000 post=761.5000 out=837.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0004s\n",
      "err: pre=8288.0000 post=940.0000 out=1016.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9200.0000 post=892.0000 out=873.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9536.0000 post=882.5000 out=933.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=697.5000 out=697.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9032.0000 post=693.0000 out=645.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=724.0000 out=694.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9056.0000 post=746.5000 out=712.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9184.0000 post=684.0000 out=726.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9096.0000 post=812.5000 out=676.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8680.0000 post=840.5000 out=762.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8792.0000 post=966.5000 out=956.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8624.0000 post=1072.0000 out=1125.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9200.0000 post=1069.0000 out=1211.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8712.0000 post=726.5000 out=583.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8464.0000 post=744.0000 out=677.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=849.5000 out=899.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7956.0000 post=943.0000 out=1037.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=959.5000 out=1104.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8544.0000 post=755.0000 out=607.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8092.0000 post=796.5000 out=776.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8144.0000 post=942.0000 out=999.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7904.0000 post=1055.0000 out=1185.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=1100.0000 out=1282.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=747.0000 out=581.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8280.0000 post=785.0000 out=703.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8560.0000 post=884.5000 out=840.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=942.0000 out=932.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8784.0000 post=997.5000 out=1135.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8296.0000 post=697.0000 out=599.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8376.0000 post=710.0000 out=725.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7988.0000 post=772.0000 out=780.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=783.5000 out=851.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8616.0000 post=779.5000 out=860.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=768.5000 out=589.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8416.0000 post=819.5000 out=821.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8304.0000 post=926.0000 out=951.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=950.0000 out=1021.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8632.0000 post=1017.0000 out=1180.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7708.0000 post=674.0000 out=568.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8140.0000 post=697.5000 out=836.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7320.0000 post=721.0000 out=668.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8592.0000 post=727.5000 out=707.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=682.5000 out=745.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7632.0000 post=684.0000 out=495.7500\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7820.0000 post=702.0000 out=714.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7616.0000 post=750.5000 out=652.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8100.0000 post=820.5000 out=741.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8136.0000 post=760.5000 out=765.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7652.0000 post=610.0000 out=499.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=641.5000 out=648.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8296.0000 post=656.5000 out=667.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9144.0000 post=669.0000 out=617.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9456.0000 post=641.5000 out=657.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8672.0000 post=659.5000 out=534.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8944.0000 post=684.5000 out=611.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9088.0000 post=695.0000 out=633.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9104.0000 post=735.5000 out=670.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9328.0000 post=689.0000 out=707.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9624.0000 post=757.5000 out=713.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8928.0000 post=782.0000 out=805.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8912.0000 post=852.5000 out=978.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8584.0000 post=1017.0000 out=1174.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8840.0000 post=1212.0000 out=1445.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9392.0000 post=667.0000 out=652.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8976.0000 post=709.0000 out=719.5000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9280.0000 post=751.0000 out=758.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9856.0000 post=818.0000 out=895.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9992.0000 post=899.0000 out=1020.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8864.0000 post=608.5000 out=552.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9056.0000 post=648.0000 out=640.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9128.0000 post=655.5000 out=639.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9600.0000 post=692.0000 out=708.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10152.0000 post=676.5000 out=708.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=629.5000 out=571.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8888.0000 post=650.0000 out=635.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=667.0000 out=635.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9520.0000 post=725.0000 out=722.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9616.0000 post=686.0000 out=714.0000\n",
      "Total sparse runtime: 0.0069s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8840.0000 post=670.0000 out=575.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9040.0000 post=726.0000 out=690.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=753.0000 out=708.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8904.0000 post=806.0000 out=781.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8528.0000 post=757.0000 out=888.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8472.0000 post=615.0000 out=513.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8608.0000 post=693.5000 out=613.5000\n",
      "Total sparse runtime: 0.0084s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8092.0000 post=693.0000 out=666.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8568.0000 post=739.0000 out=704.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8792.0000 post=696.0000 out=724.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8760.0000 post=657.5000 out=555.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=694.5000 out=624.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8424.0000 post=724.5000 out=682.0000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8720.0000 post=764.5000 out=767.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8936.0000 post=646.5000 out=677.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8248.0000 post=652.0000 out=556.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8440.0000 post=722.5000 out=667.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7752.0000 post=734.5000 out=703.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8312.0000 post=808.5000 out=800.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8104.0000 post=696.0000 out=744.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8464.0000 post=631.0000 out=533.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8872.0000 post=694.0000 out=659.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8048.0000 post=730.5000 out=681.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=790.0000 out=779.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8232.0000 post=706.5000 out=726.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7984.0000 post=595.5000 out=517.0000\n",
      "Total sparse runtime: 0.0084s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8504.0000 post=666.0000 out=618.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8016.0000 post=705.5000 out=646.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8480.0000 post=745.5000 out=723.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=685.5000 out=721.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8648.0000 post=613.0000 out=544.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9408.0000 post=652.5000 out=583.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8808.0000 post=651.5000 out=591.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9360.0000 post=661.5000 out=606.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9864.0000 post=593.5000 out=578.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8736.0000 post=637.5000 out=536.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=697.0000 out=642.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=668.0000 out=625.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9560.0000 post=727.5000 out=701.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9768.0000 post=655.5000 out=706.5000\n",
      "Total sparse runtime: 0.0156s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=608.0000 out=511.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=677.5000 out=618.5000\n",
      "Total sparse runtime: 0.0078s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8536.0000 post=699.5000 out=659.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=731.5000 out=734.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9352.0000 post=625.5000 out=650.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8416.0000 post=620.0000 out=532.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9136.0000 post=690.0000 out=624.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=705.0000 out=650.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9144.0000 post=753.0000 out=734.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9080.0000 post=641.0000 out=689.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8344.0000 post=606.0000 out=501.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9112.0000 post=706.0000 out=714.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7496.0000 post=711.0000 out=684.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9296.0000 post=769.0000 out=763.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8648.0000 post=650.5000 out=654.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8064.0000 post=606.5000 out=510.2500\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8720.0000 post=665.5000 out=596.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8216.0000 post=671.5000 out=596.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8656.0000 post=725.5000 out=739.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8824.0000 post=632.0000 out=667.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8240.0000 post=639.0000 out=509.2500\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9000.0000 post=697.0000 out=614.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8288.0000 post=727.5000 out=661.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8704.0000 post=794.5000 out=829.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8592.0000 post=664.5000 out=710.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8200.0000 post=604.5000 out=493.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8872.0000 post=657.0000 out=577.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8336.0000 post=705.5000 out=633.5000\n",
      "Total sparse runtime: 0.0060s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9176.0000 post=750.0000 out=733.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9144.0000 post=651.0000 out=672.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8336.0000 post=637.5000 out=538.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9192.0000 post=689.5000 out=623.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=689.5000 out=639.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9440.0000 post=700.0000 out=675.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10248.0000 post=639.5000 out=631.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9536.0000 post=668.0000 out=569.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10096.0000 post=714.0000 out=707.5000\n",
      "Total sparse runtime: 0.0190s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9568.0000 post=707.5000 out=662.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9904.0000 post=749.0000 out=725.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10208.0000 post=716.0000 out=716.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9816.0000 post=757.0000 out=650.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9864.0000 post=787.0000 out=863.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8816.0000 post=911.0000 out=1047.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9176.0000 post=916.5000 out=1015.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9776.0000 post=988.5000 out=1121.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9744.0000 post=745.0000 out=743.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10048.0000 post=727.5000 out=713.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9632.0000 post=755.5000 out=844.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8984.0000 post=883.0000 out=1063.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9104.0000 post=1056.0000 out=1270.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9312.0000 post=601.0000 out=534.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9944.0000 post=635.5000 out=623.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9896.0000 post=629.5000 out=587.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10840.0000 post=640.0000 out=586.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=11600.0000 post=673.5000 out=669.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0004s\n",
      "err: pre=9400.0000 post=693.0000 out=620.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9824.0000 post=708.0000 out=667.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9616.0000 post=722.0000 out=710.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10000.0000 post=728.0000 out=707.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10312.0000 post=729.5000 out=753.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9416.0000 post=751.0000 out=647.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9384.0000 post=811.5000 out=787.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9024.0000 post=894.5000 out=934.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9032.0000 post=913.0000 out=939.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9392.0000 post=905.5000 out=1013.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8688.0000 post=631.5000 out=572.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9136.0000 post=693.0000 out=638.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8504.0000 post=700.0000 out=648.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8960.0000 post=723.0000 out=698.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9064.0000 post=702.0000 out=724.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8784.0000 post=695.0000 out=551.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8744.0000 post=743.5000 out=794.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8088.0000 post=850.5000 out=950.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8792.0000 post=859.0000 out=909.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9224.0000 post=809.5000 out=928.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8624.0000 post=731.5000 out=605.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=768.5000 out=728.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=840.0000 out=830.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8952.0000 post=886.5000 out=917.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8848.0000 post=899.0000 out=1017.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8392.0000 post=717.5000 out=563.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8264.0000 post=757.0000 out=678.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8248.0000 post=863.0000 out=784.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8400.0000 post=951.0000 out=899.0000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8044.0000 post=1001.5000 out=1098.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7944.0000 post=688.5000 out=603.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8056.0000 post=730.0000 out=670.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7700.0000 post=846.5000 out=809.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8052.0000 post=945.0000 out=957.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7676.0000 post=946.0000 out=1036.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=616.5000 out=536.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8680.0000 post=645.5000 out=715.0000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7768.0000 post=668.0000 out=663.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9608.0000 post=667.5000 out=658.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9736.0000 post=615.5000 out=643.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8496.0000 post=642.5000 out=585.5000\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7992.0000 post=740.5000 out=704.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8224.0000 post=754.0000 out=715.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8552.0000 post=795.5000 out=809.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8800.0000 post=737.0000 out=797.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8208.0000 post=640.0000 out=500.7500\n",
      "Total sparse runtime: 0.0066s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8116.0000 post=680.0000 out=607.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7832.0000 post=732.5000 out=670.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8280.0000 post=787.5000 out=791.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8832.0000 post=735.5000 out=803.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8000.0000 post=652.5000 out=507.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8068.0000 post=702.5000 out=614.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7836.0000 post=738.0000 out=660.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8180.0000 post=826.5000 out=823.5000\n",
      "Total sparse runtime: 0.0067s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8164.0000 post=784.5000 out=884.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7876.0000 post=633.0000 out=479.0000\n",
      "Total sparse runtime: 0.0068s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8116.0000 post=690.0000 out=664.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7172.0000 post=775.0000 out=726.5000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8360.0000 post=860.5000 out=835.0000\n",
      "Total sparse runtime: 0.0074s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7648.0000 post=790.5000 out=828.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7868.0000 post=643.5000 out=539.0000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8344.0000 post=699.5000 out=626.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7788.0000 post=721.0000 out=643.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8180.0000 post=798.5000 out=808.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8272.0000 post=684.0000 out=754.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8032.0000 post=685.0000 out=555.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8336.0000 post=757.5000 out=698.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8096.0000 post=771.5000 out=681.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0022s\n",
      "err: pre=8080.0000 post=870.0000 out=847.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=744.5000 out=790.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7788.0000 post=634.0000 out=504.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8224.0000 post=679.5000 out=560.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7860.0000 post=737.0000 out=645.0000\n",
      "Total sparse runtime: 0.0061s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8208.0000 post=809.0000 out=768.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8448.0000 post=747.5000 out=798.0000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=7964.0000 post=641.5000 out=559.5000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8640.0000 post=668.0000 out=596.5000\n",
      "Total sparse runtime: 0.0062s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8156.0000 post=700.0000 out=674.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=8984.0000 post=721.5000 out=737.5000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9480.0000 post=668.0000 out=669.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9312.0000 post=681.0000 out=569.0000\n",
      "Total sparse runtime: 0.0065s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9768.0000 post=717.0000 out=685.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9368.0000 post=728.0000 out=696.0000\n",
      "Total sparse runtime: 0.0064s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=9784.0000 post=751.0000 out=758.5000\n",
      "Total sparse runtime: 0.0063s\n",
      "MLP runtime: 0.0002s\n",
      "err: pre=10200.0000 post=730.5000 out=793.0000\n",
      "Instruct: Write a quick song about bricks.\n",
      "\n",
      "Response:\n",
      "\n",
      "Ver 1:\n",
      "Bricks are strong, they can hold a wall\n",
      "They're made of clay, they're never to fall\n",
      "\n",
      "Chorus:\n",
      "Bricks are the building block\n",
      "They're the foundation of a home\n",
      "\n",
      "Ver 2:\n",
      "Bricks are used in construction\n",
      "They're a symbol of strength and dedication\n",
      "\n",
      "Chorus:\n",
      "Bricks are the building block\n",
      "They're the foundation of a home\n",
      "\n",
      "Bridge:\n",
      "Bricks are used in many ways\n",
      "They're a symbol of strength and dedication\n",
      "\n",
      "Chorus:\n",
      "Bricks are the building block\n",
      "They're the foundation of a home\n",
      "\n",
      "Outro:\n",
      "Bricks are the building block\n",
      "They're the foundation of a home\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# test.\n",
    "\n",
    "tokens = tokenizer(\"Instruct: Write a quick song about bricks.\\n\\nResponse:\", return_tensors=\"pt\").to('cuda')\n",
    "output = model.generate(**tokens, max_new_tokens=1000)\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6e92ff4-fef5-44f3-a132-434b4a2d27dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.1033\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sparse_post_acts = smlp.mlp.activation_fn(debug_acts[0].detach().cpu()).numpy()[0, 0]\n",
    "true_post_acts = smlp.mlp.activation_fn(debug_acts[1].detach().cpu()).numpy()[0, 0]\n",
    "\n",
    "print(true_post_acts[true_post_acts < 0].mean())\n",
    "\n",
    "# plt.hist([sparse_post_acts[true_post_acts < 0], true_post_acts[true_post_acts < 0]], bins=40, histtype=\"bar\", label=[\"sparse post acts\", \"true post acts\"])\n",
    "plt.hist([sparse_post_acts[true_post_acts < 0], true_post_acts[true_post_acts < 0]], bins=40, histtype=\"bar\", label=[\"sparse post acts\", \"true post acts\"])\n",
    "# plt.hist(, bins=40, label='true post acts')\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"activation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b00ab6-5a18-4cc4-a378-2040f9c78ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "02a5d379-7f3a-418c-80fa-660d8303638d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created HNSW lookup table in 10.9962 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def quick_test():\n",
    "    mlp = model.model.layers[0].mlp\n",
    "\n",
    "    # Use inner product as a \"distance metric\". This is actually perfect for our case though,\n",
    "    # where MLP activations are scaled according to inner product.\n",
    "    p = hnswlib.Index(space='ip', dim=mlp.fc1.in_features + 1)\n",
    "\n",
    "    # Add weight matrix to encoder.\n",
    "    p.init_index(max_elements=mlp.fc1.out_features)\n",
    "\n",
    "    ids = np.arange(mlp.fc1.out_features)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # mlp.fc1.weight.shape: [10240, 2560]\n",
    "    # we add a bias so we can query for that inner product as well\n",
    "    match_vecs = np.concatenate([\n",
    "        mlp.fc1.weight.detach().cpu().numpy(),\n",
    "        mlp.fc1.bias.detach().cpu().unsqueeze(-1).numpy(),\n",
    "    ], axis=-1)\n",
    "    p.add_items(match_vecs, ids)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Created HNSW lookup table in {end_time - start_time:.4f} s\")\n",
    "    \n",
    "    print((mlp.fc2.weight[:, [10, 20, 30, 40]] @ torch.tensor([1, 2, 3, 4], device='cuda', dtype=torch.float16)).shape)\n",
    "    \n",
    "    tokens = tokenizer(\"Sparse is fast\", return_tensors=\"pt\")\n",
    "\n",
    "    embeddings = model.model.embed_tokens(tokens.input_ids.cuda())\n",
    "\n",
    "    # ef should be greater than k.\n",
    "    # it is the size of the list used during nearest neighbor search.\n",
    "    num_neighbors = 100\n",
    "    p.set_ef(int(num_neighbors * 2))\n",
    "\n",
    "    embedding = np.zeros(2561)\n",
    "    embedding[:-1] = embeddings[0, 0].detach().cpu().numpy()\n",
    "    embedding[-1] = 1\n",
    "\n",
    "    labels, _distances = p.knn_query(embedding, k=num_neighbors)\n",
    "\n",
    "    # labels = np.arange(10240)\n",
    "    labels = torch.tensor(labels.astype(np.int64), device=\"cuda\").long()\n",
    "\n",
    "    print(mlp.fc1.weight.shape)\n",
    "\n",
    "    # recompute distances\n",
    "    inner_products = mlp.fc1.weight[labels] @ embeddings[0, 0]\n",
    "\n",
    "    # labels = np.arange(10240)\n",
    "    # distances = 1 - match_vecs @ embeddings[0, 0].detach().cpu().numpy()\n",
    "\n",
    "    # print(distances.shape)\n",
    "\n",
    "    # print(labels.shape, distances.shape)\n",
    "\n",
    "    # distances = 1 - inner product\n",
    "    # labels = ids\n",
    "\n",
    "    activations_recons = mlp.fc1.bias.data.clone()\n",
    "    activations_recons[labels] += inner_products\n",
    "    activations = mlp.activation_fn(activations_recons)\n",
    "    reconstructed_activation = mlp.fc2.weight @ activations + mlp.fc2.bias\n",
    "\n",
    "    # selected_decoder_vecs = mlp.fc2.weight[:, labels]\n",
    "    # reconstructed_activation = torch.einsum('ds,s->d', mlp.fc2.weight, activations)\n",
    "\n",
    "    # pre_activations = torch.tensor(1 - distances, device=\"cuda\", dtype=mlp.fc2.weight.dtype)\n",
    "    # activations = mlp.activation_fn(pre_activations)\n",
    "    # selected_decoder_vecs = mlp.fc2.weight[:, labels]\n",
    "    # reconstructed_activation = torch.einsum('ds,s->d', selected_decoder_vecs, activations)\n",
    "\n",
    "    print(labels.shape)\n",
    "    print(selected_decoder_vecs.shape)\n",
    "    print(activations.shape)\n",
    "    print(reconstructed_activation.shape)\n",
    "\n",
    "    true_activation = mlp(embeddings[0, 0])\n",
    "\n",
    "    print(torch.abs(reconstructed_activation - true_activation).sum())\n",
    "\n",
    "    true_activation, reconstructed_activation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
