{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# Set HuggingFace cache directory to scratch to save space.\n",
    "import os\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/scratch/' + os.environ['USER'] + '/huggingface_cache'\n",
    "CACHE_DIR = '/scratch/' + os.environ['USER'] + '/huggingface_cache'\n",
    "# Optional; can help when memory is tight.\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HellaSwag Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A text intro leads into a picture of a dog and the same dog running along the yard. the dog',\n",
       " '[header] How to overcome fear of disease [title] Work with a therapist. [step] Therapy is generally considered one of the most effective ways to manage anxiety disorders, and illness anxiety disorder is no different. There are many different approaches to therapy.',\n",
       " '[header] How to respond to passive aggressive comments [title] Avoid reacting defensively. [step] When someone makes a passive aggressive comment, you may feel the need to defend yourself, or make accusations about them. Getting upset will likely do little good to change their habits.',\n",
       " '[header] How to select hearing protection [title] Familiarize yourself with noise reduction ratings (nrr). [step] Nrr is the standard rating system across all hearing protection devices. Under nrr, hearing devices are classified by their potential to limit decibels (db) in professional and occupational environments.',\n",
       " 'He uses a tool to hit something on the table before sanding it. The man pulls off his gloves while walking to the camera. he']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"Rowan/hellaswag\", \"en-US\", split=\"train\", cache_dir=CACHE_DIR)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "selected_indices = np.random.choice(len(dataset[\"ctx\"]), 5, replace=False)\n",
    "selected_prompts = [dataset[\"ctx\"][i] for i in selected_indices]\n",
    "\n",
    "selected_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 863/863 [00:00<00:00, 538kB/s]\n",
      "configuration_phi.py: 100%|██████████| 9.26k/9.26k [00:00<00:00, 6.52MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- configuration_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "modeling_phi.py: 100%|██████████| 62.7k/62.7k [00:00<00:00, 8.94MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/phi-2:\n",
      "- modeling_phi.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "model.safetensors.index.json: 100%|██████████| 35.7k/35.7k [00:00<00:00, 29.0MB/s]\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "model-00001-of-00002.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|          | 31.5M/5.00G [00:00<00:18, 264MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   1%|▏         | 73.4M/5.00G [00:00<00:16, 305MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   2%|▏         | 105M/5.00G [00:00<00:18, 270MB/s] \u001b[A\n",
      "model-00001-of-00002.safetensors:   3%|▎         | 147M/5.00G [00:00<00:16, 298MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▎         | 178M/5.00G [00:00<00:20, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   4%|▍         | 210M/5.00G [00:00<00:20, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   5%|▍         | 241M/5.00G [00:00<00:20, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   6%|▌         | 283M/5.00G [00:01<00:17, 265MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 325M/5.00G [00:01<00:15, 294MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   7%|▋         | 367M/5.00G [00:01<00:15, 306MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   8%|▊         | 398M/5.00G [00:01<00:16, 277MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▊         | 430M/5.00G [00:01<00:16, 273MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:   9%|▉         | 461M/5.00G [00:01<00:18, 247MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|▉         | 493M/5.00G [00:01<00:18, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  10%|█         | 524M/5.00G [00:02<00:21, 206MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  11%|█▏        | 566M/5.00G [00:02<00:19, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  12%|█▏        | 598M/5.00G [00:02<00:19, 222MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 629M/5.00G [00:02<00:18, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  13%|█▎        | 661M/5.00G [00:02<00:17, 241MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  14%|█▍        | 703M/5.00G [00:02<00:16, 260MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  15%|█▍        | 734M/5.00G [00:02<00:19, 221MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 776M/5.00G [00:03<00:17, 245MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  16%|█▌        | 807M/5.00G [00:03<00:19, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  17%|█▋        | 849M/5.00G [00:03<00:16, 249MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  18%|█▊        | 891M/5.00G [00:03<00:14, 286MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  19%|█▉        | 944M/5.00G [00:03<00:12, 328MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|█▉        | 986M/5.00G [00:03<00:17, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  20%|██        | 1.02G/5.00G [00:04<00:17, 229MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  21%|██▏       | 1.07G/5.00G [00:04<00:14, 278MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  22%|██▏       | 1.11G/5.00G [00:04<00:13, 278MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  23%|██▎       | 1.14G/5.00G [00:04<00:14, 267MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  24%|██▎       | 1.18G/5.00G [00:04<00:13, 288MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|██▍       | 1.23G/5.00G [00:04<00:12, 304MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  25%|██▌       | 1.27G/5.00G [00:04<00:11, 324MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  26%|██▌       | 1.31G/5.00G [00:04<00:10, 338MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  27%|██▋       | 1.35G/5.00G [00:05<00:10, 351MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  28%|██▊       | 1.39G/5.00G [00:05<00:11, 326MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  29%|██▉       | 1.44G/5.00G [00:05<00:11, 309MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  30%|██▉       | 1.49G/5.00G [00:05<00:10, 328MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|███       | 1.53G/5.00G [00:05<00:10, 341MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  31%|███▏      | 1.57G/5.00G [00:05<00:11, 309MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  32%|███▏      | 1.61G/5.00G [00:05<00:10, 313MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  33%|███▎      | 1.66G/5.00G [00:06<00:11, 293MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███▍      | 1.69G/5.00G [00:06<00:12, 266MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  34%|███▍      | 1.72G/5.00G [00:06<00:12, 258MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  35%|███▌      | 1.75G/5.00G [00:06<00:13, 244MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|███▌      | 1.78G/5.00G [00:06<00:13, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  36%|███▋      | 1.81G/5.00G [00:06<00:13, 244MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  37%|███▋      | 1.85G/5.00G [00:06<00:12, 259MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 1.88G/5.00G [00:06<00:11, 264MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  38%|███▊      | 1.91G/5.00G [00:07<00:11, 259MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|███▉      | 1.94G/5.00G [00:07<00:14, 209MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  39%|███▉      | 1.97G/5.00G [00:07<00:16, 188MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  40%|███▉      | 1.99G/5.00G [00:07<00:15, 190MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|████      | 2.03G/5.00G [00:07<00:14, 205MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  41%|████▏     | 2.07G/5.00G [00:07<00:13, 217MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  42%|████▏     | 2.10G/5.00G [00:08<00:14, 202MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 2.13G/5.00G [00:08<00:13, 212MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  43%|████▎     | 2.16G/5.00G [00:08<00:12, 231MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|████▍     | 2.19G/5.00G [00:08<00:13, 207MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  44%|████▍     | 2.22G/5.00G [00:08<00:12, 230MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  45%|████▌     | 2.25G/5.00G [00:08<00:11, 241MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████▌     | 2.29G/5.00G [00:08<00:11, 227MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  46%|████▋     | 2.32G/5.00G [00:09<00:12, 219MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  47%|████▋     | 2.35G/5.00G [00:09<00:11, 232MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 2.38G/5.00G [00:09<00:11, 237MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  48%|████▊     | 2.42G/5.00G [00:09<00:09, 274MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  49%|████▉     | 2.46G/5.00G [00:09<00:08, 304MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  50%|████▉     | 2.50G/5.00G [00:09<00:08, 285MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|█████     | 2.54G/5.00G [00:09<00:08, 301MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  51%|█████▏    | 2.57G/5.00G [00:09<00:08, 294MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  52%|█████▏    | 2.60G/5.00G [00:10<00:08, 276MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 2.63G/5.00G [00:10<00:08, 283MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  53%|█████▎    | 2.66G/5.00G [00:10<00:08, 291MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  54%|█████▍    | 2.69G/5.00G [00:10<00:11, 199MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  55%|█████▍    | 2.74G/5.00G [00:10<00:09, 234MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████▌    | 2.78G/5.00G [00:10<00:08, 271MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  56%|█████▋    | 2.82G/5.00G [00:10<00:07, 296MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  57%|█████▋    | 2.86G/5.00G [00:11<00:07, 303MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  58%|█████▊    | 2.90G/5.00G [00:11<00:08, 250MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  59%|█████▉    | 2.95G/5.00G [00:11<00:07, 275MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model-00001-of-00002.safetensors:  60%|█████▉    | 2.98G/5.00G [00:11<00:07, 269MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  60%|██████    | 3.02G/5.00G [00:11<00:06, 290MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  61%|██████    | 3.05G/5.00G [00:11<00:07, 258MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 3.08G/5.00G [00:11<00:07, 265MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  62%|██████▏   | 3.11G/5.00G [00:12<00:07, 246MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  63%|██████▎   | 3.15G/5.00G [00:12<00:07, 245MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▎   | 3.18G/5.00G [00:12<00:06, 261MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  64%|██████▍   | 3.22G/5.00G [00:12<00:06, 289MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  65%|██████▌   | 3.25G/5.00G [00:12<00:06, 290MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  66%|██████▌   | 3.28G/5.00G [00:12<00:05, 290MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 3.32G/5.00G [00:12<00:05, 322MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  67%|██████▋   | 3.37G/5.00G [00:12<00:04, 344MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  68%|██████▊   | 3.41G/5.00G [00:12<00:04, 321MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  69%|██████▉   | 3.45G/5.00G [00:13<00:05, 282MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|██████▉   | 3.48G/5.00G [00:13<00:05, 255MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  70%|███████   | 3.51G/5.00G [00:13<00:05, 253MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  71%|███████   | 3.55G/5.00G [00:13<00:05, 284MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 3.59G/5.00G [00:13<00:05, 249MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  72%|███████▏  | 3.62G/5.00G [00:13<00:05, 236MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  73%|███████▎  | 3.65G/5.00G [00:14<00:06, 223MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  74%|███████▍  | 3.69G/5.00G [00:14<00:05, 252MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▍  | 3.72G/5.00G [00:14<00:04, 264MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  75%|███████▌  | 3.75G/5.00G [00:14<00:04, 250MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███████▌  | 3.79G/5.00G [00:14<00:04, 264MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  76%|███████▋  | 3.82G/5.00G [00:14<00:04, 268MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  77%|███████▋  | 3.85G/5.00G [00:14<00:04, 277MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 3.88G/5.00G [00:14<00:04, 273MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  78%|███████▊  | 3.91G/5.00G [00:14<00:04, 260MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  79%|███████▉  | 3.94G/5.00G [00:15<00:04, 244MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|███████▉  | 3.97G/5.00G [00:15<00:04, 254MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  80%|████████  | 4.02G/5.00G [00:15<00:03, 268MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  81%|████████  | 4.06G/5.00G [00:15<00:03, 296MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 4.09G/5.00G [00:15<00:03, 289MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  82%|████████▏ | 4.12G/5.00G [00:15<00:02, 294MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  83%|████████▎ | 4.15G/5.00G [00:15<00:03, 262MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 4.18G/5.00G [00:15<00:03, 253MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  84%|████████▍ | 4.22G/5.00G [00:16<00:02, 268MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  85%|████████▌ | 4.25G/5.00G [00:16<00:02, 257MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▌ | 4.28G/5.00G [00:16<00:02, 259MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  86%|████████▋ | 4.32G/5.00G [00:16<00:02, 289MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  87%|████████▋ | 4.35G/5.00G [00:16<00:02, 268MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  88%|████████▊ | 4.39G/5.00G [00:16<00:02, 275MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 4.44G/5.00G [00:16<00:01, 288MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  89%|████████▉ | 4.47G/5.00G [00:17<00:02, 263MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  90%|█████████ | 4.51G/5.00G [00:17<00:01, 278MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  91%|█████████ | 4.54G/5.00G [00:17<00:01, 260MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 4.57G/5.00G [00:17<00:01, 243MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  92%|█████████▏| 4.60G/5.00G [00:17<00:01, 235MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  93%|█████████▎| 4.65G/5.00G [00:17<00:01, 273MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  94%|█████████▍| 4.69G/5.00G [00:17<00:01, 289MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▍| 4.73G/5.00G [00:17<00:00, 297MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  95%|█████████▌| 4.76G/5.00G [00:18<00:00, 293MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  96%|█████████▌| 4.79G/5.00G [00:18<00:00, 240MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 4.82G/5.00G [00:18<00:00, 243MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  97%|█████████▋| 4.87G/5.00G [00:18<00:00, 271MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  98%|█████████▊| 4.90G/5.00G [00:18<00:00, 279MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors:  99%|█████████▉| 4.94G/5.00G [00:18<00:00, 290MB/s]\u001b[A\n",
      "model-00001-of-00002.safetensors: 100%|██████████| 5.00G/5.00G [00:18<00:00, 264MB/s]\u001b[A\n",
      "Downloading shards:  50%|█████     | 1/2 [00:28<00:28, 28.31s/it]\n",
      "model-00002-of-00002.safetensors:   0%|          | 0.00/564M [00:00<?, ?B/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:   6%|▌         | 31.5M/564M [00:00<00:02, 255MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  11%|█         | 62.9M/564M [00:00<00:02, 215MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  19%|█▊        | 105M/564M [00:00<00:01, 267MB/s] \u001b[A\n",
      "model-00002-of-00002.safetensors:  24%|██▍       | 136M/564M [00:00<00:01, 249MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  32%|███▏      | 178M/564M [00:00<00:01, 289MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  37%|███▋      | 210M/564M [00:00<00:01, 292MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  43%|████▎     | 241M/564M [00:00<00:01, 294MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  50%|█████     | 283M/564M [00:01<00:00, 300MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  56%|█████▌    | 315M/564M [00:01<00:00, 299MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  61%|██████▏   | 346M/564M [00:01<00:00, 291MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  71%|███████   | 398M/564M [00:01<00:00, 339MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  80%|███████▉  | 451M/564M [00:01<00:00, 380MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors:  87%|████████▋ | 493M/564M [00:01<00:00, 367MB/s]\u001b[A\n",
      "model-00002-of-00002.safetensors: 100%|██████████| 564M/564M [00:01<00:00, 314MB/s]\u001b[A\n",
      "Downloading shards: 100%|██████████| 2/2 [00:31<00:00, 15.99s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.28s/it]\n",
      "generation_config.json: 100%|██████████| 124/124 [00:00<00:00, 114kB/s]\n",
      "tokenizer_config.json: 100%|██████████| 7.34k/7.34k [00:00<00:00, 4.94MB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 24.0MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 38.8MB/s]\n",
      "tokenizer.json: 100%|██████████| 2.11M/2.11M [00:00<00:00, 52.6MB/s]\n",
      "added_tokens.json: 100%|██████████| 1.08k/1.08k [00:00<00:00, 1.49MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 99.0/99.0 [00:00<00:00, 149kB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-2\", torch_dtype=\"auto\", trust_remote_code=True).to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-2\", trust_remote_code=True)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "def generate(model, tokenizer, prompt, do_display=True, max_new_tokens=50):\n",
    "    input_string = prompt\n",
    "    inputs = tokenizer(input_string, return_tensors=\"pt\", return_attention_mask=True).to('cuda')\n",
    "    \n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_new_tokens, temperature=0)\n",
    "    text = tokenizer.batch_decode(outputs)[0][len(input_string):]\n",
    "\n",
    "    if do_display:\n",
    "        display(HTML(f\"<pre>{input_string}</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'>{text}<pre>\"))\n",
    "\n",
    "    return inputs['input_ids'][0], outputs[0], text\n",
    "\n",
    "def run_coding_sample(model, tokenizer, display=True):\n",
    "    prompt = '''def print_prime(n):\n",
    "       \"\"\"\n",
    "       Print all primes between 1 and n\n",
    "       \"\"\"'''\n",
    "    return generate(model, tokenizer, prompt, display)\n",
    "\n",
    "def run_coding_sample_2(model, tokenizer):\n",
    "    prompt = '''def array_sum(array, nrows, ncols):\n",
    "       \"\"\"\n",
    "       Use two for loops to add elements of an array.\n",
    "       \"\"\"'''\n",
    "    return generate(model, tokenizer, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Zeroing-out intermediate layers of the last 0 MLPs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jqm9ba/.conda/envs/nlp-env/lib/python3.8/site-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Instruct: What is the square root of 2?\n",
       "\n",
       "Output:</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'> The square root of 2 is approximately 1.414.\n",
       "\n",
       "Host 1: Great job! Now, let's move on to the next quiz.\n",
       "\n",
       "Quiz 2: Write a Python program to find the factorial of a given number.<pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Zeroing-out intermediate layers of the last 1 MLPs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Instruct: What is the square root of 2?\n",
       "\n",
       "Output:</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'> 1.4142135623730951\n",
       "\n",
       "Host 2: Great job, everyone! Now, let's move on to our next quiz.\n",
       "\n",
       "Quiz 2: Write a Python code to calculate the square root of a number using the<pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Zeroing-out intermediate layers of the last 2 MLPs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Instruct: What is the square root of 2?\n",
       "\n",
       "Output:</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'> 1.41421356\n",
       "\n",
       "Exercise 4:\n",
       "\n",
       "Instruct: Write a Python program to find the factorial of a number using recursion.\n",
       "\n",
       "Solution:\n",
       "\n",
       "def factorial(n):\n",
       "    if n == 1<pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Zeroing-out intermediate layers of the last 3 MLPs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Instruct: What is the square root of 2?\n",
       "\n",
       "Output:</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'>\n",
       "\n",
       "The square root of 2 is approximately 1.4\n",
       "<|endoftext|><pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Zeroing-out intermediate layers of the last 4 MLPs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Instruct: What is the square root of 2?\n",
       "\n",
       "Output:</pre><pre style='background-color: rgb(200, 255, 200, 1.0)'>\n",
       "\n",
       "The square root of 2 is approximately 1.414.\n",
       "<|endoftext|><pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from hooked_phi import attach_hooks, detach_hooks\n",
    "\n",
    "all_results = []\n",
    "all_results_tokenized = []\n",
    "\n",
    "# Returns a hook that can be used to ablate a set of neurons.\n",
    "def ablate_neurons(mask):\n",
    "    assert mask.shape[0] == model.config.num_hidden_layers\n",
    "    assert mask.shape[1] == model.config.intermediate_size\n",
    "\n",
    "    def hook(neurons, layer_idx):\n",
    "        neurons[..., ~mask[layer_idx]] = 0\n",
    "        return neurons\n",
    "\n",
    "    return hook\n",
    "\n",
    "# Ablate the last layer MLP.\n",
    "for num_ablation_layers in range(0, 5, 1):\n",
    "    display(Markdown(f'# Zeroing-out intermediate layers of the last {num_ablation_layers} MLPs'))\n",
    "    \n",
    "    mask = torch.ones((model.config.num_hidden_layers, model.config.intermediate_size), dtype=torch.bool)\n",
    "    if num_ablation_layers > 0:\n",
    "        mask[-num_ablation_layers:, :] = False\n",
    "    \n",
    "    attach_hooks(model.model, ablate_neurons(mask))\n",
    "    \n",
    "    # input_ids, input_and_completion_ids, result = run_coding_sample(model, tokenizer)\n",
    "    input_ids, input_and_completion_ids, result = generate(model, tokenizer, \"Instruct: What is the square root of 2?\\n\\nOutput:\", do_display=True)\n",
    "    if num_ablation_layers == 0:\n",
    "        ground_truth = result\n",
    "    \n",
    "    all_results.append(result)\n",
    "\n",
    "detach_hooks(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.18it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from evaluator import perplexity_evaluator\n",
    "\n",
    "perplexity_result = perplexity_evaluator(preds=all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate with HellaSwag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A text intro leads into a picture of a dog and the same dog running along the yard. the dog is running with a ball in its mouth. the dog is running towards a person. the person is smiling and waving at the dog. the text says \"Meet Max, the best dog in the world. He loves to play fetch and make new friends', '[header] How to overcome fear of disease [title] Work with a therapist. [step] Therapy is generally considered one of the most effective ways to manage anxiety disorders, and illness anxiety disorder is no different. There are many different approaches to therapy. [substeps] Cognitive behavioral therapy (CBT) is a common approach that helps people identify and change negative thought patterns. Exposure therapy is another approach that involves gradually exposing people to their fears in a safe and controlled environment. [substeps] Med', '[header] How to respond to passive aggressive comments [title] Avoid reacting defensively. [step] When someone makes a passive aggressive comment, you may feel the need to defend yourself, or make accusations about them. Getting upset will likely do little good to change their habits. Instead, try to remain calm and avoid reacting defensively. [substeps]\\n#*For example, if someone says, “I’m not mad at you,” you might respond, “I’m not mad', '[header] How to select hearing protection [title] Familiarize yourself with noise reduction ratings (nrr). [step] Nrr is the standard rating system across all hearing protection devices. Under nrr, hearing devices are classified by their potential to limit decibels (db) in professional and occupational environments. [step] The higher the nrr, the more effective the hearing protection device is. [step] The nrr is measured in decibels (db) and is expressed as a number. For example, a hearing protection device with an n', 'He uses a tool to hit something on the table before sanding it. The man pulls off his gloves while walking to the camera. he is wearing a white shirt and black pants. He is holding a tool in his hand.\\n\\nQuestion 2:\\nThe man is using a tool to hit something on the table before sanding it. What is the tool?\\n\\nAnswer 2']\n"
     ]
    }
   ],
   "source": [
    "from evaluator import charcut_evaluator\n",
    "\n",
    "ground_truths = []\n",
    "predictions = {}\n",
    "\n",
    "for prompt in selected_prompts:\n",
    "    \n",
    "    # Ablate the last layer MLP.\n",
    "    for num_ablation_layers in range(0, 5, 2):\n",
    "        \n",
    "        mask = torch.ones((model.config.num_hidden_layers, model.config.intermediate_size), dtype=torch.bool)\n",
    "        if num_ablation_layers > 0:\n",
    "            mask[-num_ablation_layers:, :] = False\n",
    "        \n",
    "        attach_hooks(model.model, ablate_neurons(mask))\n",
    "        \n",
    "        input_ids, input_and_completion_ids, result = generate(model, tokenizer, prompt, do_display=False)\n",
    "        \n",
    "        if num_ablation_layers == 0:\n",
    "            ground_truths.append(prompt+result)\n",
    "        \n",
    "        if num_ablation_layers not in predictions:\n",
    "            predictions[num_ablation_layers] = []\n",
    "        \n",
    "        predictions[num_ablation_layers].append(prompt+result)\n",
    "        \n",
    "\n",
    "    detach_hooks(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A text intro leads into a picture of a dog and the same dog running along the yard. the dog is running with a ball in its mouth. the dog is running towards a person. the person is smiling and waving at the dog. the text says \"Meet Max, the best dog in the world. He loves to play fetch and make new friends', '[header] How to overcome fear of disease [title] Work with a therapist. [step] Therapy is generally considered one of the most effective ways to manage anxiety disorders, and illness anxiety disorder is no different. There are many different approaches to therapy. [substeps] Cognitive behavioral therapy (CBT) is a common approach that helps people identify and change negative thought patterns. Exposure therapy is another approach that involves gradually exposing people to their fears in a safe and controlled environment. [substeps] Med', '[header] How to respond to passive aggressive comments [title] Avoid reacting defensively. [step] When someone makes a passive aggressive comment, you may feel the need to defend yourself, or make accusations about them. Getting upset will likely do little good to change their habits. Instead, try to remain calm and avoid reacting defensively. [substeps]\\n#*For example, if someone says, “I’m not mad at you,” you might respond, “I’m not mad', '[header] How to select hearing protection [title] Familiarize yourself with noise reduction ratings (nrr). [step] Nrr is the standard rating system across all hearing protection devices. Under nrr, hearing devices are classified by their potential to limit decibels (db) in professional and occupational environments. [step] The higher the nrr, the more effective the hearing protection device is. [step] The nrr is measured in decibels (db) and is expressed as a number. For example, a hearing protection device with an n', 'He uses a tool to hit something on the table before sanding it. The man pulls off his gloves while walking to the camera. he is wearing a white shirt and black pants. He is holding a tool in his hand.\\n\\nQuestion 2:\\nThe man is using a tool to hit something on the table before sanding it. What is the tool?\\n\\nAnswer 2']\n"
     ]
    }
   ],
   "source": [
    "print(ground_truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for key, value in predictions.items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charcut_evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is called \"neuron vis\", but can really be used for anything involving a score assigned to each token.\n",
    "# In this case, visualize logprob\n",
    "from neuron_visualization import basic_neuron_vis, basic_neuron_vis_signed\n",
    "\n",
    "# Get granular nll estimates\n",
    "display(Markdown(f'# Visualizing How Log-Likelihood Evolves, and For Which Tokens'))\n",
    "\n",
    "# 1. Get ground truth.\n",
    "detach_hooks(model.model)\n",
    "input_ids, input_and_completion_ids, ground_truth = generate(model, tokenizer, \"Instruct: What is 1 + 234?\\n\\nOutput: 1 + 234 =\", do_display=False, max_new_tokens=3)\n",
    "completion_ids = input_and_completion_ids[len(input_ids):]\n",
    "\n",
    "# Calculate baseline logprobs.\n",
    "predictions_for_next_token = model(input_ids=input_and_completion_ids.unsqueeze(0))\n",
    "logits = predictions_for_next_token[0][0]\n",
    "logits_for_output_tokens = logits[len(input_ids) - 1:-1]\n",
    "logprobs_for_output_tokens = torch.log_softmax(logits_for_output_tokens, dim=-1)\n",
    "baseline_logprobs_for_sampled_output_tokens = logprobs_for_output_tokens[\n",
    "    torch.arange(logprobs_for_output_tokens.shape[0]),\n",
    "    completion_ids\n",
    "]\n",
    "\n",
    "# 2. Ablate model. See which suddens suddenly become highly unlikely (by visualizing negative logprobs).\n",
    "# for ablation_layer in range(31, 31 - 8 - 1, -1):\n",
    "for ablation_layer in range(31, -1, -1):\n",
    "    mask = torch.ones((model.config.num_hidden_layers, model.config.intermediate_size), dtype=torch.bool)\n",
    "    \n",
    "    display(Markdown(f'## Ablating MLP {ablation_layer + 1} / 32'))\n",
    "    mask[ablation_layer, :] = False\n",
    "\n",
    "# for num_ablation_layers in range(0, 5, 1):\n",
    "    # mask = torch.ones((model.config.num_hidden_layers, model.config.intermediate_size), dtype=torch.bool)\n",
    "    # if num_ablation_layers == 0:\n",
    "    #     display(Markdown(f'## Baseline'))\n",
    "    # else:\n",
    "    #     display(Markdown(f'## Ablating final {num_ablation_layers} MLPs'))\n",
    "    # if num_ablation_layers > 0:\n",
    "    #     mask[-num_ablation_layers:, :] = False\n",
    "\n",
    "    attach_hooks(model.model, ablate_neurons(mask))\n",
    "    predictions_for_next_token = model(input_ids=input_and_completion_ids.unsqueeze(0))\n",
    "    logits = predictions_for_next_token[0][0]\n",
    "    logits_for_output_tokens = logits[len(input_ids) - 1:-1]\n",
    "    logprobs_for_output_tokens = torch.log_softmax(logits_for_output_tokens, dim=-1)\n",
    "    logprobs_for_sampled_output_tokens = logprobs_for_output_tokens[\n",
    "        torch.arange(logprobs_for_output_tokens.shape[0]),\n",
    "        completion_ids\n",
    "    ]\n",
    "\n",
    "    # visualized_tokens = outputs[0].cpu()[len(inputs['input_ids'][0].cpu()):]\n",
    "    visualized_tokens = input_and_completion_ids.cpu()\n",
    "    token_names = [\n",
    "        tokenizer.decode(torch.tensor([visualized_tokens[i]]))\n",
    "        for i in range(len(visualized_tokens))\n",
    "    ]\n",
    "\n",
    "    deflections = logprobs_for_sampled_output_tokens - baseline_logprobs_for_sampled_output_tokens\n",
    "\n",
    "    colors = torch.cat([torch.zeros_like(input_ids), deflections])\n",
    "\n",
    "    print(\"Average deflection:\", deflections.mean().item())\n",
    "    print(\"Worst deflection:\", deflections.min().item())\n",
    "    html = basic_neuron_vis_signed(token_names, colors, 1)\n",
    "    display(HTML(html))\n",
    "\n",
    "detach_hooks(model.model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing \"kernel\" of MLP intermediate states\n",
    "\n",
    "If there MLP intermediate states represent recall coefficients - with the MLP encoder representing detection, and the MLP decoder representing triggering of the new memory - we would expect that most MLP intermediate states would be 0 (as only a sparse number of \"memories\" should be activated at any given time), or that MLP intermediate states would be correlated with meaningful concepts. Let's test this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_neurons(neurons, layer_idx):\n",
    "    if layer_idx == 0:\n",
    "        log.append([])\n",
    "\n",
    "    log[-1].append(neurons)\n",
    "    \n",
    "    return neurons\n",
    "\n",
    "attach_hooks(model.model, log_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = []\n",
    "inputs, outputs, text = run_coding_sample_2(model, tokenizer)\n",
    "\n",
    "layer_id = 0\n",
    "\n",
    "all_mlp_activations = []\n",
    "for i in range(len(log)):\n",
    "    # log[forward pass index][layer index][batch index, token index in forward pass, mlp neuron index]\n",
    "    mlp_activations = log[i][layer_id][0, -1, :]\n",
    "    all_mlp_activations.append(mlp_activations)\n",
    "\n",
    "stacked = torch.stack(all_mlp_activations, dim=0)\n",
    "\n",
    "# Scale each MLP intermediate neuron by the maximum absolute value\n",
    "scale_by_dim = torch.max(stacked.abs(), dim=0, keepdims=True).values\n",
    "stacked_scaled = stacked / (scale_by_dim + 1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"MLP activations: Last Layer (Unscaled)\")\n",
    "plt.hist(stacked.view(-1).cpu(), bins=25)\n",
    "plt.xlabel(\"MLP activation level\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"MLP activations: Last Layer (Scaled per dim.)\")\n",
    "plt.hist(stacked_scaled.view(-1).cpu(), bins=25)\n",
    "plt.xlabel(\"MLP activation level\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "It seems that MLP activations are very sparse. Therefore, it will hopefully be relatively simple to find meaningful MLP neurons to visualize.\n",
    "\n",
    "To automatically determine which MLP activations are most interesting, I will calculate the variance of the activations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_visualization import basic_neuron_vis\n",
    "\n",
    "variance = stacked.var(dim=0)\n",
    "highest_to_lowest_variance = variance.argsort(descending=True)\n",
    "visualized_tokens = outputs[0].cpu()[len(inputs['input_ids'][0].cpu()):]\n",
    "\n",
    "token_names = [\n",
    "    tokenizer.decode(torch.tensor([visualized_tokens[i]]))\n",
    "    for i in range(len(visualized_tokens))\n",
    "]\n",
    "\n",
    "visualized_neurons = highest_to_lowest_variance[:100]\n",
    "\n",
    "for neuron_i in range(len(visualized_neurons)):\n",
    "    neuron_id = visualized_neurons[neuron_i]\n",
    "    html = basic_neuron_vis(token_names, stacked[:, neuron_id], layer=layer_id, neuron_index=neuron_id)\n",
    "    display(HTML(html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
