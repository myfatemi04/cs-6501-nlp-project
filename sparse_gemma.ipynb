{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8ad956e-a35a-4ff9-b25a-72c56649b695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import transformer_lens\n",
    "import sparse_autoencoder\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b5744f9-9909-4880-b04d-3abf218fcb91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sparse_autoencoder.autoencoder.model import SparseAutoencoder\n",
    "sae_gemma = SparseAutoencoder.load(\"/scratch/mbf3zk/.checkpoints/curious-sweep-1_100941824.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a7cc686-711e-4a01-a651-5174b71a519e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (pre_encoder_bias): TiedBias(position=pre_encoder)\n",
       "  (encoder): LinearEncoder(\n",
       "    input_features=2048, learnt_features=16384, n_components=6\n",
       "    (activation_function): ReLU()\n",
       "  )\n",
       "  (decoder): UnitNormDecoder(learnt_features=16384, decoded_features=2048, n_components=6)\n",
       "  (post_decoder_bias): TiedBias(position=post_decoder)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae_gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8faf9fb-e116-4bc2-bec2-44860f86b8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4695ca70bc432c9c9704f092e954aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1e7d599f7f466faadafec382de10b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540c77c7f14e4c3abfbc0313d23bce4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/33.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f9f237d20e40e4bef57c9720836c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765cff4583614bfc9547ed6b3897e0ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:You are not using LayerNorm, so the writing weights can't be centered! Skipping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model google/gemma-2b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = transformer_lens.HookedTransformer.from_pretrained(\"google/gemma-2b\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2baaa51-d6c0-4104-8bdc-7cfc72e46e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 134217728000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msparse_autoencoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msource_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstore_activations_hook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m store_activations_hook\n\u001b[0;32m---> 11\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mTensorActivationStore\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m component_idx, cache_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.hook_mlp_out\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m6\u001b[39m)]):\n\u001b[1;32m     13\u001b[0m     hook \u001b[38;5;241m=\u001b[39m partial(store_activations_hook, store\u001b[38;5;241m=\u001b[39mstore, component_idx\u001b[38;5;241m=\u001b[39mcomponent_idx)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pydantic/validate_call_decorator.py:58\u001b[0m, in \u001b[0;36mvalidate_call.<locals>.validate.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(function)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidate_call_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:81\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 81\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[1;32m     83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[0;32m~/.conda/envs/sparse/lib/python3.11/site-packages/sparse_autoencoder/activation_store/tensor_store.py:99\u001b[0m, in \u001b[0;36mTensorActivationStore.__init__\u001b[0;34m(self, max_items, n_neurons, n_components, device)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items_stored \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m n_components\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_items \u001b[38;5;241m=\u001b[39m max_items\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neurons\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:83] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 134217728000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# from sparse_autoencoder.autoencoder.model import SparseAutoencoderConfig\n",
    "#     config = SparseAutoencoderConfig(\n",
    "#         n_input_features=autoencoder_input_dim,\n",
    "#         n_learned_features=autoencoder_input_dim * 8,\n",
    "#         n_components=len(hyperparameters[\"source_model\"][\"cache_names\"]),\n",
    "#     )\n",
    "from sparse_autoencoder.activation_store.tensor_store import TensorActivationStore\n",
    "from functools import partial\n",
    "from sparse_autoencoder.source_model.store_activations_hook import store_activations_hook\n",
    "\n",
    "store = TensorActivationStore(1000, 2048, 2048 * 8)\n",
    "for component_idx, cache_name in enumerate([f\"blocks.{layer}.hook_mlp_out\" for layer in range(6)]):\n",
    "    hook = partial(store_activations_hook, store=store, component_idx=component_idx)\n",
    "    model.add_hook(cache_name, hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8665519d-f8c5-4176-8835-d6eb5b621337",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (pre_encoder_bias): TiedBias(position=pre_encoder)\n",
       "  (encoder): LinearEncoder(\n",
       "    input_features=2048, learnt_features=16384, n_components=6\n",
       "    (activation_function): ReLU()\n",
       "  )\n",
       "  (decoder): UnitNormDecoder(learnt_features=16384, decoded_features=2048, n_components=6)\n",
       "  (post_decoder_bias): TiedBias(position=post_decoder)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "sae_gemma.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f70174f2-37ee-431a-b77a-d11c58f26e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topic_sentences = {\n",
    "    topic: [\n",
    "        x[2:] for x in open(f\"example_sentences/{topic}.txt\").read().split(\"\\n\")\n",
    "    ] for topic in ['math', 'physics', 'chemistry']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1a0ab5c-5219-476d-989c-9b5786a9673b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28, 6, 16384])\n",
      "torch.Size([28, 6, 2048])\n"
     ]
    }
   ],
   "source": [
    "i_text = \"Euler's identity, e^(iπ) + 1 = 0, is considered one of the most beautiful equations in mathematics.\"\n",
    "with torch.no_grad():\n",
    "    o = model.forward(i_text, stop_at_layer=7, prepend_bos=False)\n",
    "    o = o.permute(1, 0, 2)\n",
    "    learned_activations, reconstructed_activations = sae_gemma.forward(o)\n",
    "\n",
    "\n",
    "print(learned_activations.shape)\n",
    "print(reconstructed_activations.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d074a6e4-71f0-4df5-b5fe-55c9803b7c4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation 1: Token 1, Layer 2, Feature 15407, Value 26.51151466369629\n",
      "Activation 2: Token 1, Layer 4, Feature 13500, Value 25.717500686645508\n",
      "Activation 3: Token 1, Layer 2, Feature 4885, Value 25.02952003479004\n",
      "Activation 4: Token 1, Layer 4, Feature 10154, Value 22.379722595214844\n",
      "Activation 5: Token 2, Layer 2, Feature 15407, Value 21.33807945251465\n",
      "Activation 6: Token 1, Layer 5, Feature 6412, Value 20.741857528686523\n",
      "Activation 7: Token 2, Layer 4, Feature 13500, Value 20.249370574951172\n",
      "Activation 8: Token 2, Layer 2, Feature 4885, Value 20.015485763549805\n",
      "Activation 9: Token 3, Layer 2, Feature 15407, Value 18.33335304260254\n",
      "Activation 10: Token 3, Layer 2, Feature 4885, Value 17.913307189941406\n",
      "Activation 11: Token 2, Layer 4, Feature 10154, Value 17.830551147460938\n",
      "Activation 12: Token 3, Layer 4, Feature 13500, Value 17.742000579833984\n",
      "Activation 13: Token 1, Layer 3, Feature 4131, Value 17.403520584106445\n",
      "Activation 14: Token 1, Layer 2, Feature 12636, Value 17.352413177490234\n",
      "Activation 15: Token 1, Layer 3, Feature 6640, Value 17.03888511657715\n",
      "Activation 16: Token 1, Layer 1, Feature 11163, Value 16.79534339904785\n",
      "Activation 17: Token 2, Layer 5, Feature 6412, Value 16.563505172729492\n",
      "Activation 18: Token 4, Layer 2, Feature 15407, Value 15.792222023010254\n",
      "Activation 19: Token 4, Layer 4, Feature 13500, Value 15.756624221801758\n",
      "Activation 20: Token 4, Layer 2, Feature 4885, Value 15.531686782836914\n",
      "Activation 21: Token 6, Layer 2, Feature 15407, Value 15.397750854492188\n",
      "Activation 22: Token 6, Layer 2, Feature 4885, Value 15.33124828338623\n",
      "Activation 23: Token 1, Layer 4, Feature 10876, Value 14.66112995147705\n",
      "Activation 24: Token 6, Layer 4, Feature 13500, Value 14.597771644592285\n",
      "Activation 25: Token 24, Layer 2, Feature 15407, Value 14.592175483703613\n",
      "Activation 26: Token 26, Layer 2, Feature 15407, Value 14.492953300476074\n",
      "Activation 27: Token 3, Layer 5, Feature 6412, Value 14.491939544677734\n",
      "Activation 28: Token 8, Layer 2, Feature 15407, Value 14.487499237060547\n",
      "Activation 29: Token 1, Layer 3, Feature 10524, Value 14.447797775268555\n",
      "Activation 30: Token 25, Layer 4, Feature 13500, Value 14.443656921386719\n",
      "Activation 31: Token 1, Layer 4, Feature 14719, Value 14.4310302734375\n",
      "Activation 32: Token 1, Layer 4, Feature 1548, Value 14.351195335388184\n",
      "Activation 33: Token 25, Layer 2, Feature 15407, Value 14.31995677947998\n",
      "Activation 34: Token 26, Layer 4, Feature 13500, Value 14.019085884094238\n",
      "Activation 35: Token 1, Layer 0, Feature 15881, Value 13.995427131652832\n",
      "Activation 36: Token 8, Layer 2, Feature 4885, Value 13.97799301147461\n",
      "Activation 37: Token 1, Layer 3, Feature 8497, Value 13.942319869995117\n",
      "Activation 38: Token 3, Layer 4, Feature 10154, Value 13.86706829071045\n",
      "Activation 39: Token 1, Layer 5, Feature 3985, Value 13.8662691116333\n",
      "Activation 40: Token 4, Layer 4, Feature 10154, Value 13.754179000854492\n",
      "Activation 41: Token 8, Layer 4, Feature 13500, Value 13.697406768798828\n",
      "Activation 42: Token 27, Layer 2, Feature 15407, Value 13.670019149780273\n",
      "Activation 43: Token 26, Layer 2, Feature 4885, Value 13.66813850402832\n",
      "Activation 44: Token 2, Layer 3, Feature 6640, Value 13.660351753234863\n",
      "Activation 45: Token 7, Layer 2, Feature 15407, Value 13.453742027282715\n",
      "Activation 46: Token 25, Layer 2, Feature 4885, Value 13.41640567779541\n",
      "Activation 47: Token 1, Layer 3, Feature 8413, Value 13.306434631347656\n",
      "Activation 48: Token 2, Layer 2, Feature 12636, Value 13.215461730957031\n",
      "Activation 49: Token 27, Layer 4, Feature 13500, Value 13.17204475402832\n",
      "Activation 50: Token 5, Layer 2, Feature 15407, Value 13.072136878967285\n",
      "Activation 51: Token 24, Layer 2, Feature 4885, Value 13.065136909484863\n",
      "Activation 52: Token 11, Layer 2, Feature 15407, Value 12.996384620666504\n",
      "Activation 53: Token 2, Layer 3, Feature 4131, Value 12.989984512329102\n",
      "Activation 54: Token 6, Layer 4, Feature 10154, Value 12.888593673706055\n",
      "Activation 55: Token 6, Layer 5, Feature 6412, Value 12.87193775177002\n",
      "Activation 56: Token 1, Layer 3, Feature 15459, Value 12.809834480285645\n",
      "Activation 57: Token 1, Layer 2, Feature 2919, Value 12.784442901611328\n",
      "Activation 58: Token 24, Layer 4, Feature 13500, Value 12.77483081817627\n",
      "Activation 59: Token 1, Layer 5, Feature 680, Value 12.702840805053711\n",
      "Activation 60: Token 7, Layer 2, Feature 4885, Value 12.691597938537598\n",
      "Activation 61: Token 7, Layer 4, Feature 13500, Value 12.688675880432129\n",
      "Activation 62: Token 4, Layer 5, Feature 6412, Value 12.644620895385742\n",
      "Activation 63: Token 25, Layer 4, Feature 10154, Value 12.643472671508789\n",
      "Activation 64: Token 19, Layer 2, Feature 4885, Value 12.63418960571289\n",
      "Activation 65: Token 23, Layer 2, Feature 15407, Value 12.630655288696289\n",
      "Activation 66: Token 5, Layer 4, Feature 13500, Value 12.528624534606934\n",
      "Activation 67: Token 2, Layer 1, Feature 11163, Value 12.465025901794434\n",
      "Activation 68: Token 5, Layer 2, Feature 4885, Value 12.434648513793945\n",
      "Activation 69: Token 11, Layer 4, Feature 13500, Value 12.43175983428955\n",
      "Activation 70: Token 23, Layer 2, Feature 4885, Value 12.332185745239258\n",
      "Activation 71: Token 27, Layer 2, Feature 4885, Value 12.307010650634766\n",
      "Activation 72: Token 16, Layer 4, Feature 13500, Value 12.247502326965332\n",
      "Activation 73: Token 1, Layer 5, Feature 10080, Value 12.236726760864258\n",
      "Activation 74: Token 13, Layer 4, Feature 13500, Value 12.209619522094727\n",
      "Activation 75: Token 2, Layer 4, Feature 1548, Value 12.20821475982666\n",
      "Activation 76: Token 8, Layer 4, Feature 10154, Value 12.082938194274902\n",
      "Activation 77: Token 23, Layer 4, Feature 13500, Value 12.051596641540527\n",
      "Activation 78: Token 5, Layer 4, Feature 10154, Value 12.033435821533203\n",
      "Activation 79: Token 27, Layer 4, Feature 10154, Value 11.991715431213379\n",
      "Activation 80: Token 19, Layer 4, Feature 13500, Value 11.953482627868652\n",
      "Activation 81: Token 19, Layer 2, Feature 15407, Value 11.9331636428833\n",
      "Activation 82: Token 2, Layer 0, Feature 15881, Value 11.885336875915527\n",
      "Activation 83: Token 3, Layer 3, Feature 6640, Value 11.772808074951172\n",
      "Activation 84: Token 1, Layer 4, Feature 8370, Value 11.741165161132812\n",
      "Activation 85: Token 10, Layer 4, Feature 13500, Value 11.643622398376465\n",
      "Activation 86: Token 1, Layer 1, Feature 13301, Value 11.578824043273926\n",
      "Activation 87: Token 13, Layer 2, Feature 4885, Value 11.561491012573242\n",
      "Activation 88: Token 1, Layer 1, Feature 5603, Value 11.54738998413086\n",
      "Activation 89: Token 2, Layer 3, Feature 8497, Value 11.466201782226562\n",
      "Activation 90: Token 17, Layer 4, Feature 13500, Value 11.398428916931152\n",
      "Activation 91: Token 20, Layer 4, Feature 13500, Value 11.361201286315918\n",
      "Activation 92: Token 26, Layer 4, Feature 10154, Value 11.35595989227295\n",
      "Activation 93: Token 1, Layer 3, Feature 15311, Value 11.30858039855957\n",
      "Activation 94: Token 3, Layer 1, Feature 11163, Value 11.25937271118164\n",
      "Activation 95: Token 18, Layer 2, Feature 4885, Value 11.248733520507812\n",
      "Activation 96: Token 16, Layer 2, Feature 4885, Value 11.246803283691406\n",
      "Activation 97: Token 25, Layer 5, Feature 6412, Value 11.242140769958496\n",
      "Activation 98: Token 18, Layer 4, Feature 13500, Value 11.23138427734375\n",
      "Activation 99: Token 24, Layer 4, Feature 10154, Value 11.222545623779297\n",
      "Activation 100: Token 18, Layer 2, Feature 15407, Value 11.207618713378906\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Flatten the tensor to a 2D tensor where each row is a token-layer combination\n",
    "learned_activations_pruned = learned_activations[1:]\n",
    "flattened_activations = learned_activations_pruned.reshape(-1, 16384)  # Shape will be [96, 16384] as 16*6 = 96\n",
    "\n",
    "# Step 2: Sort the activations to find the top 100. We use topk which also gives the indices\n",
    "top_values, top_indices = torch.topk(flattened_activations.flatten(), 100)\n",
    "\n",
    "# The top_indices now contains the linear indices of the top 100 activations in the flattened view\n",
    "# We can convert these indices back to the original token-layer-feature indices\n",
    "top_token_layer_indices = top_indices // 16384  # Get which token-layer combination it is\n",
    "top_feature_indices = top_indices % 16384  # Get which feature index within that token-layer combination\n",
    "\n",
    "# Step 3: If needed, translate indices back to (token, layer, feature) format\n",
    "top_tokens = top_token_layer_indices // 6  # There are 6 layers\n",
    "top_layers = top_token_layer_indices % 6\n",
    "\n",
    "# Print or return the results\n",
    "for i in range(100):\n",
    "    print(f\"Activation {i+1}: Token {top_tokens[i] + 1}, Layer {top_layers[i]}, Feature {top_feature_indices[i]}, Value {top_values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9766b955-92ea-4e6e-b25e-05ab4e47a29b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: black'><span class='token' style='background-color:rgb(150.06005406379697, 240, 150.06005406379697)'><bos></span><span class='token' style='background-color:rgb(165.8209228515625, 240, 165.8209228515625)'>Euler</span><span class='token' style='background-color:rgb(164.5682716369629, 240, 164.5682716369629)'>'</span><span class='token' style='background-color:rgb(188.35221767425534, 240, 188.35221767425534)'>s</span><span class='token' style='background-color:rgb(183.97000074386597, 240, 183.97000074386597)'>&nbsp;identity</span><span class='token' style='background-color:rgb(170.56913614273068, 240, 170.56913614273068)'>,</span><span class='token' style='background-color:rgb(181.59058332443234, 240, 181.59058332443234)'>&nbsp;e</span><span class='token' style='background-color:rgb(166.33665800094604, 240, 166.33665800094604)'>^(</span><span class='token' style='background-color:rgb(193.4992814064026, 240, 193.4992814064026)'>i</span><span class='token' style='background-color:rgb(187.32486009597775, 240, 187.32486009597775)'>π</span><span class='token' style='background-color:rgb(191.4936566352844, 240, 191.4936566352844)'>)</span><span class='token' style='background-color:rgb(189.039226770401, 240, 189.039226770401)'>&nbsp;+</span><span class='token' style='background-color:rgb(189.5537757873535, 240, 189.5537757873535)'>&nbsp;</span><span class='token' style='background-color:rgb(193.50087881088254, 240, 193.50087881088254)'>1</span><span class='token' style='background-color:rgb(188.38922023773193, 240, 188.38922023773193)'>&nbsp;=</span><span class='token' style='background-color:rgb(194.94757294654843, 240, 194.94757294654843)'>&nbsp;</span><span class='token' style='background-color:rgb(189.82327222824097, 240, 189.82327222824097)'>0</span><span class='token' style='background-color:rgb(178.6875212192535, 240, 178.6875212192535)'>,</span><span class='token' style='background-color:rgb(179.18062448501587, 240, 179.18062448501587)'>&nbsp;is</span><span class='token' style='background-color:rgb(182.51060485839844, 240, 182.51060485839844)'>&nbsp;considered</span><span class='token' style='background-color:rgb(187.52025604248047, 240, 187.52025604248047)'>&nbsp;one</span><span class='token' style='background-color:rgb(182.87052750587463, 240, 182.87052750587463)'>&nbsp;of</span><span class='token' style='background-color:rgb(175.06754636764526, 240, 175.06754636764526)'>&nbsp;the</span><span class='token' style='background-color:rgb(176.17027401924133, 240, 176.17027401924133)'>&nbsp;most</span><span class='token' style='background-color:rgb(181.9392883777618, 240, 181.9392883777618)'>&nbsp;beautiful</span><span class='token' style='background-color:rgb(172.48761892318726, 240, 172.48761892318726)'>&nbsp;equations</span><span class='token' style='background-color:rgb(195.95861077308655, 240, 195.95861077308655)'>&nbsp;in</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import neuron_visualization\n",
    "from IPython.display import display, HTML, display_markdown\n",
    "\n",
    "tokens = model.to_tokens(i_text)\n",
    "token_str = model.to_str_tokens(tokens)\n",
    "aggregated_activations = learned_activations_pruned.mean(dim=[1, 2])\n",
    "max_activation = aggregated_activations.abs().max().item()\n",
    "display(HTML(neuron_visualization.basic_neuron_vis_signed(token_str, aggregated_activations.tolist(), .6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4b580-bfa4-4ea0-8860-cfe17099bcb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparse",
   "language": "python",
   "name": "sparse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
